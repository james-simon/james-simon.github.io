<!DOCTYPE html>
<html>

  <head>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>J S</title>
  <meta name="description" content="">

  <!-- <link href="/bootstrap/css/bootstrap.css" rel="stylesheet">
  <script src="/boostrap/js/bootstrap.js"></script> -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/">
  <link rel="alternate" type="application/rss+xml" title="J S" href="http://localhost:4000/feed.xml">

  

</head>


  <body>

    <!-- <header class="site-header"> -->
    <!-- <a class="site-title" href="/">J S</a> -->
<!-- </header> -->

    <nav class="navbar navbar-expand-lg navbar-light" style="background-color: #edf3f5;">
      <div class = "container">
        <a class="navbar-brand" href="/">J S</a></span> </a>
        <div class="collapse navbar-collapse">
          <ul class="nav navbar-nav ml-auto">
            <li class = "nav-item active"><a class="nav-link" href="/#research"><i class="fas fa-cogs"></i> Research</a></li>
            <li class = "nav-item active"><a class="nav-link" href="/#puzzles"><i class="fab fa-laravel"></i> Puzzles</a></li>
            <li class = "nav-item active"><a class="nav-link" href="/#posts"><i class="fas fa-seedling"></i> Posts</a></li>
          </ul> 
        </div>
      </div>
    </nav>

    <div class="page-content">
      <div class="wrapper">
        <link rel="stylesheet" href="css/hover_effects.css">

<style>
a:link {
  color: #225599;
  background-color: transparent;
  text-decoration: none;
}
a:visited {
  color: #552299;
  background-color: transparent;
  text-decoration: none;
}
.hr-thin {
    border: none;
    height: 1px;
    color: #aaaaaa;
    background-color: #aaaaaa;
}
.hr-thick {
    border: none;
    height: 2px;
    color: #aaaaaa;
    background-color: #aaaaaa;
}
.blurb {
    font-size: 80%;
}
.paper-info {
    font-size: 80%;
    margin-top: -1em;
}
</style>

<!-- <hr class="hr-thick"> -->

<!-- <div class="col-lg-3 col-md-4 col-sm-6 col-xs-12">
    <div class="hovereffect">
        <img class="img-responsive" src="https://james-simon.github.io/img/headshot.png" alt="">
        <div class="overlay">
           <a class="info" href="#">link here</a>
        </div>
    </div>
</div>
 -->

<!-- <div class="container">
  <img src="https://mdbootstrap.com/img/Photos/Others/forest-sm.jpg" alt="Avatar" class="overlay-image">
  <div class="overlay">
    <div class="overlay-text">Hello World</div>
  </div>
</div>
 -->
<br>

<div class="container">
   <a name = "about"></a>
   <div  class="media">
      <div  class="pull-left media-top">
         <div class="mr-4">
            <div class="hovereffect">
               <img class="img-responsive" src="https://james-simon.github.io/img/headshot.png" height="210px">
               <div class="tint"></div>
               <a class="hoverinfo hover1" style="font-size:xx-small;" href="">This is me about to do a 100' rope swing off El Capitan in Yosemite</a>
               <a class="hoverinfo hover2" style="font-size:xx-small;" href="">Actually, I guess this was taken just after swinging, but the rest is right</a>
               <a class="hoverinfo hover3" style="font-size:xx-small;" href="">Well, actually, the swing was only 30', but everything else is definitely the truth</a>
               <a class="hoverinfo hover4" style="font-size:xx-small;" href="">Okay, fine, it wasn't El Capitan, it was just a rock in Delaware, but I swear the rest is real</a>
               <a class="hoverinfo hover5" style="font-size:xx-small;" href="">Fine, I didn't actually swing, I just held a rope, but the idea is the same</a>
               <a class="hoverinfo hover6" style="font-size:xx-small;" href="">Alright, alright, I'll come clean: the original story was true</a>
            </div>
         </div>
      </div>
      <div class="media-body col-lg-12">
         <h1>Jamie Simon</h1>

         <p>I am a 2nd-year PhD student in the physics department at UC Berkeley, aiming to use tools from theoretical physics to build fundamental understanding of machine learning methods. I'm advised by <a href="https://deweeselab.com/">Mike DeWeese</a> and supported by an NSF Graduate Research Fellowship. In my free time, I like running, puzzles, spending time in forests, and balancing things.</p>
      </div>
   </div>

   <hr class="hr-thin">


   <a name = "research"></a>
   <h2>Research</h2>
   <hr class="hr-thick">


   <div class="row">
      <div class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/shallow_learning_sketch.png" width=100%>
      </div>
      <div class="col-md-9">
         <h3>On the Power of Shallow Learning</h3>
         <strong>Reverse-engineering the neural network-kernel method equivalence</strong>
         <p class="blurb">
            Much of our understanding of artificial neural networks stems from the fact that, in the infinite-width limit, they turn out to be equivalent to a class of simple models called <i>kernel methods.</i> Given a wide network architecture, it's surprisingly easy to find the equivalent kernel method, allowing us to study popular models in the infinite-width limit. In recent work with Sajant Anand, I showed that, for fully-connected nets (FCNs), this mapping can be run in reverse: given a desired kernel, we can work backwards to find a network that achieves it. Surprisingly, we can always design this network to have only a single hidden layer, and we used that fact to prove that wide shallow FCNs can achieve any kernel a deep FCN can, an analytical conclusion our experiments support. This ability to design nets with desired kernels is a step towards deriving good net architectures <i>from first principles</i>, a longtime dream of the field of machine learning.
         </p>
         <p class="paper-info">
            <strong>(2021)</strong>
            <strong><em>In Submission</em></strong>
            <a href="https://arxiv.org/abs/2106.03186v1">[arXiv]</a>
            <a href="https://github.com/james-simon/shallow-learning">[code]</a>
         </p>
      </div>
   </div>

   <hr class="hr-thick">

   <div class="row">
      <div  class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/GRFtest.gif" width="100%">
      </div>
      <div class="col-md-9">
         <h3>A phenomenological theory of high-dimensional optimization</h3>
         <p class="blurb">
            I'm currently working on a phenomenological field-theory-based model of high-dimensional loss surfaces that'll hopefully faithfully capture several emprical features of real neural net loss surfaces. I aim for my model to explain the Hessian loss-index relationship, agree with findings that datasets have <a href="https://arxiv.org/abs/1804.08838">intrinsic dimensions</a>, and shed light on <a href="https://arxiv.org/abs/1802.10026">mode connectivity</a>. This research direction was the subject of my proposal for the NSF-GRFP.
         </p>
      </div>
   </div>

   <hr class="hr-thick">

   <div class="row">
      <div class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/net_diagrams/net_diagram_rules.png" width="100%">
      </div>
      <div class="col-md-9">
         <h3>Alternative neural network formulations</h3>
         <p class="blurb">
            One current direction of my research involves exploring variants on the classic neural network design that are still able to do complex deep learning tasks. Much evidence in the last few years indicates that the magic of neural networks lies in their hierarchical nonlinear structure, not in the low-level details of their mathematical formulation, so this project's aiming to explore other, new deep learning models to build an understanding of what the requirements are for a model to learn complex patterns. I've written up some of my progress on one variant <a href="/deep learning/2020/08/31/multiplicative-neural-nets">here.</a>
         </p>
      </div>
   </div>

   <hr class="hr-thick">

   <div class="row">
      <div class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/trajectories.png" width="100%">
      </div>
      <div class="col-md-9">
         <h3>Critical Point-Finding Methods Reveal Gradient-Flat Regions of Deep Network Losses</h3>
         <strong>Exposing flaws in widely-used critical-point-finding methods</strong>
         <p class="blurb">
            Despite how common and useful neural networks are, there are still basic mysteries about how they work, many related to properties of their loss surfaces.  In this project, led by <a href="https://charlesfrye.github.io/">Charles Frye</a>, we tested Newton methods (common tools for optimization and exploring function structure) on loss surfaces.  We found that, as opposed to finding critical points as designed, in practice Newton methods almost always converged to a different, spurious class of points which we described.  Giving simple visualizable examples to illustrate the problem, we showed that some major studies using Newton methods on loss surfaces probably misinterpreted their results.  Our paper is <a href="https://arxiv.org/pdf/2003.10397.pdf">here</a>.
         </p>
         <p class="paper-info">
            <strong>(2021)</strong>
            <a href="https://direct.mit.edu/neco/article/33/6/1469/100574/Critical-Point-Finding-Methods-Reveal-Gradient">[Neural Computation]</a>
            <a href="https://arxiv.org/abs/2106.03186v1">[arXiv]</a><a href="https://github.com/charlesfrye/autocrit">[code]</a>
         </p>
      </div>
   </div>

   <hr class="hr-thick">

   <div class="row">
      <div class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/jj.png" width="100%">
      </div>
      <div class="col-md-9">
         <h3>Simplified Josephson-junction fabrication process for reproducibly high-performance superconducting qubits</h3>
         <strong>A faster method to make Josephson junctions</strong>
         <p class="blurb">
            In the spring and summer of 2019 I worked in the lab of Prof. <a href="http://www.chalmers.se/en/staff/Pages/per-delsing.aspx">Per Delsing</a> developing nanofabrication methods for Josephson junctions, ubiquitous components in superconducting circuitry.  My main project was a study of how junctions age in the months after fabrication, but my biggest contribution was elsewhere: Anita Fadavi, Amr Osman and I developed a junction design that is faster to fabricate by one lithography step, or potentially several days of work.
         </p>
         <p class="paper-info">
            <strong>(2021)</strong>
            <a href="https://aip.scitation.org/doi/full/10.1063/5.0037093">[Applied Physics Letters]</a></p>
      </div>
   </div>

   <hr class="hr-thick">

   <div class="row">
      <div class="col-md-3">
         <img class="mr-4" src="https://james-simon.github.io/img/statediagram.png" width="100%">
      </div>
      <div class="col-md-9">
         <h3>Fast noise-resistant control of donor nuclear spin qubits in silicon</h3>
         <strong>Better control schemes for for spin qubits</strong>
         <p class="blurb">
            Qubits decohere and lose their quantum information when uncontrollably coupled to their environment.  Nuclear spin qubits in silicon are extremely weakly coupled to their environment, giving them long coherence times (up to minutes), but that same weak coupling makes quickly controlling them difficult.  Advised by Prof. <a href="http://www1.phys.vt.edu/~economou/index.html">Sophia Economou</a>, I came up with schemes for driving nuclear spin qubits that give fast, noise-resistant arbitrary single-qubit gates.  The most important gate is a long sweep that effectively turns uncertainty in electric field (charge noise) into uncertainty in time, which can be accounted for by corrective gates.  We also show two-qubit gates.
         </p>
         <p class="paper-info">
            <strong>(2020)</strong>
            <a href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.101.205307">[PRB]</a>
            <a href="https://arxiv.org/pdf/2001.10029.pdf">[arXiv]</a></p>
      </div>
   </div>

   <hr class="hr-thick">

<!--    <div  class="media">
      <div  class="pull-left media-top" width=250px>
         <br>
         <img class="mr-4" src="https://james-simon.github.io/img/shallow_learning_sketch.png" width=250px>
      </div>
      <div class="media-body">
         <h3>On the Power of Shallow Learning</h3>
         <strong>Reverse-engineering the neural network-kernel method equivalence</strong>
         <p class="blurb">
            Much of our understanding of artificial neural networks stems from the fact that, in the infinite-width limit, they turn out to be equivalent to a class of simple models called <i>kernel methods.</i> Given a wide network architecture, it's surprisingly easy to find the equivalent kernel method, allowing us to study popular models in the infinite-width limit. In recent work with Sajant Anand, I showed that, for fully-connected nets (FCNs), this mapping can be run in reverse: given a desired kernel, we can work backwards to find a network that achieves it. Surprisingly, we can always design this network to have only a single hidden layer, and we used that fact to prove that wide shallow FCNs can achieve any kernel a deep FCN can, an analytical conclusion our experiments support. This ability to design nets with desired kernels is a step towards deriving good net architectures <i>from first principles</i>, a longtime dream of the field of machine learning.
         </p>
         <p class="paper-info">
            <strong>(2021)</strong>
            <strong><em>In Submission</em></strong>
            <a href="https://arxiv.org/abs/2106.03186v1">[arXiv]</a>
            <a href="https://github.com/james-simon/shallow-learning">[code]</a>
         </p>
      </div>
   </div> -->

   <a name="puzzles"></a>
   <h2>Puzzles</h2>
   <p>While a senior in undergrad, I started a puzzlehunt called the <a href="vthunt.com">VT Hunt</a> with Bennett Witcher.  It became a <a href="https://en.wikipedia.org/wiki/VT_Hunt">university tradition</a>, with the 2019, '20, and '21 VT Hunts each drawing 1000-2000 participants and raising money for charities.  I've also helped concoct six other puzzle events starting in high school.  A few of my favorite puzzles I've made are below. The easiest is Flags, and the most satisfying to solve, in my view, is Maelstrom.</p>

<!--    
   
   
   
   
   
   <a href="/puzzles/addersmultiplying">Adders Multiplying</a>
   
   
   
   
   
   
   
   
   • <a href="/puzzles/flags">Flags</a>
   
   
   
   
   
   
   
   
   • <a href="/puzzles/forestson">Forest Son</a>
   
   
   
   
   
   
   
   
   
   
   • <a href="/puzzles/maelstrom">Maelstrom</a>
   
   
   
   
   
   
   
   
   • <a href="/puzzles/mining">Mining</a>
   
   
   
   
   
   
   
   
   • <a href="/puzzles/topology">Topology</a>
   
   
   
   
   
   
   
   
   • <a href="/puzzles/transit">Transit</a>
   
   
   
    -->

<style>
   .center-cropped {
     object-fit: cover; /* Do not scale the image */
     object-position: center; /* Center the image within the element */
     height: 200px;
     width: 200px;
   }
</style>
<div class="row justify-content-md-center">
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/addersmultiplying.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/addersmultiplying"><h4>ADDERS MULTIPLYING</h4></a>
      </div>
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/flags.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/flags"><h4>FLAGS</h4></a>
      </div>
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/forestson.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/forestson"><h4>FOREST SON</h4></a>
      </div>
   
   
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/maelstrom.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/maelstrom"><h4>MAELSTROM</h4></a>
      </div>
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/mining.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/mining"><h4>MINING</h4></a>
      </div>
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/topology.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/topology"><h4>TOPOLOGY</h4></a>
      </div>
   
   
   
   
   
      <div class="hovereffect" style="border:2px solid black; margin: 10px 10px 10px 10px">
         <img class="center-cropped" src="https://james-simon.github.io/img/transit.png">
         <div class="tint"></div>
         <a class="hoverinfo" href="/puzzles/transit"><h4>TRANSIT</h4></a>
      </div>
   
   
</div>


   <hr class="hr-thick">

   <a name="posts"></a>
   <h2>Posts</h2>
   <ul class="post-list">
      
      <li>
         <span class="post-meta">Nov 29, 2020</span>
         <h4>
            <a class="post-link" href="/physics/2020/11/29/rocketball">Could you propel a spacecraft using sports projectiles?</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Sep 6, 2020</span>
         <h4>
            <a class="post-link" href="/physics/2020/09/06/least_power_dissipation">The principle of least power dissipation</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Aug 31, 2020</span>
         <h4>
            <a class="post-link" href="/deep%20learning/2020/08/31/multiplicative-neural-nets">Multiplicative neural networks</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Aug 20, 2020</span>
         <h4>
            <a class="post-link" href="/physics/2020/08/20/upside-down-candle">How would an upside-down candle burn?</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Jul 12, 2020</span>
         <h4>
            <a class="post-link" href="/mail/2020/07/12/mail-shenanigans">Messing with the postal service</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Jul 4, 2020</span>
         <h4>
            <a class="post-link" href="/society/2020/07/04/common-ground">Common ground</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Jun 17, 2020</span>
         <h4>
            <a class="post-link" href="/physics/2020/06/17/fish-planet">What would happen if you made a planet out of fish?</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">Jun 17, 2020</span>
         <h4>
            <a class="post-link" href="/physics/2020/06/17/chicken-cooking">How hard do you have to hit a chicken to cook it?</a>
         </h4>
      </li>
      
      <li>
         <span class="post-meta">May 17, 2020</span>
         <h4>
            <a class="post-link" href="/stats/2020/05/17/covid-calculation">The expected cost of breaking quarantine</a>
         </h4>
      </li>
      
   </ul>

</div>


</div>
      </div>
    </div>

    <div class="text-center p-3" style="background-color: #edf3f5;">
  <div class="container ">
    <div class="row justify-content-md-center">

      <div class="col-2">
        <p class="text-center">
          <i class="far fa-envelope"></i>
          <a href="mailto:jsi@berkeley.edu">jsi@berkeley.edu</a>
        </p>
      </div>

      <div class="col-2">
        <p class="text-center">
          <i class="fab fa-github"></i>
          <a href="https://github.com/james-simon">james-simon</a>
        </p>
      </div>

      <div class="col-2">
        <p class="text-center">
          <i class="fas fa-graduation-cap"></i>
          <a href=>gScholar</a>
        </p>
      </div>

      <div class="col-2">
        <p class="text-center">
          <i class="fab fa-instagram"></i>
          <a href="https://instagram.com/sam.simon17">sam.simon17</a>
        </p>
      </div>

      <div class="col-2">
        <p class="text-center">
          SSN: 574-05-7179
        </p>
      </div>

    </div>
  </div>
</div>
</footer>

  </body>

</html>
