<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JS</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 25 Jul 2024 01:49:52 -0700</pubDate>
    <lastBuildDate>Thu, 25 Jul 2024 01:49:52 -0700</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>The time I caught an egg in my mouth</title>
        <description>&lt;!-- This one is exactly what it sounds like. --&gt;
&lt;p&gt;Of all my recent years’ varied adventures, the most memorable ten seconds might well have been when my housemate tossed me an egg and I caught it in my mouth.
The hour was 9am.
The egg was raw.
The music was high.
It was our first try.
It looked a little like this.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;80%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/eggman/EGGMAN.MP4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;p&gt;I suppose one could look for a deeper meaning here, some lesson on spontanaeity or the pursuit of the comic absurd or the value of attempting things that seem impossible, but no: this one’s just an egg, and it was awesome.
The satisfying ka-&lt;em&gt;chunk&lt;/em&gt; of the egg clinking off my teeth and lodging unbroken in my mouth like a heavy-duty mechanism locking into place stayed with me all day.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Thanks to Irian D’Andrea for the grade-A toss and to Olive Eilbott for both issuing the challenge and capturing it on video.&lt;/p&gt;
</description>
        <pubDate>Fri, 05 Jul 2024 01:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/egg/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/egg/</guid>
        
        
        <category>random</category>
        
      </item>
    
      <item>
        <title>Experiments in self-assembly</title>
        <description>&lt;p&gt;In 2018, I designed and prototyped a series of self-assembling objects.
I never published anything about it then, so I’m doing it now.
I’ll give background and my motivation, show some cute demos, and conclude with some reflections.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;I’ve always liked cute interactive technical projects. This was particularly true in college, during which I made lots of mostly-useless-but-fun things, including&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a laser-activated light switch&lt;/li&gt;
  &lt;li&gt;a robotic articulated necktie&lt;/li&gt;
  &lt;li&gt;various 3D printed ball mazes&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://james-simon.github.io/blog/gravitrees/&quot;&gt;lots of balancing sculptures&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;and &lt;a href=&quot;vthunt.com&quot;&gt;a campus-wide puzzlehunt&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I thought self-assembling systems and other passive mechanics were particularly cool — some demos that inspired me included &lt;a href=&quot;https://www.youtube.com/watch?v=Bnj1sPfo4Ek&quot;&gt;this self-assembling “chair,”&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=6aZbJS6LZbs&quot;&gt;this swarm of cubic robots&lt;/a&gt;, and this &lt;a href=&quot;https://www.youtube.com/watch?v=ZVYz7g-qLjs&quot;&gt;robot origami&lt;/a&gt;, all from MIT. As a senior, I got a small grant from the 3D printing service &lt;a href=&quot;https://www.notion.so/Self-assembly-blogpost-ba25260acc7948a3b9c7343548521687?pvs=21&quot;&gt;Shapeways&lt;/a&gt; to explore 3D printed self-assembling systems.&lt;/p&gt;

&lt;p&gt;I spent a semester on the project and came up with some cool prototypes. None of them are particularly scalable or practical, but they are cute.&lt;/p&gt;

&lt;h3 id=&quot;self-assembling-circuit&quot;&gt;Self-assembling circuit&lt;/h3&gt;

&lt;p&gt;I designed a self-assembling circuit. It consists of four pieces, each of which has two magnetic surfaces to link up to its two neighbors. The four pieces are hollow and contain circuit components: a battery, a resistor, an LED, and a blank wire, respectively. When all four pieces are joined in a loop, the LED lights up. As far as I know, this is the first self-assembling circuit ever made (as long as you don’t count naturally-occurring circuits in biochemistry!).&lt;/p&gt;

&lt;p&gt;The four pieces will link up after being shaken together for a minute or two. Here’s a demo video:&lt;/p&gt;

&lt;!-- youtube embed. pretty cursed -- no idea how this is working --&gt;
&lt;style&gt;
    .video-container {
        position: relative;
        width: 60%; /* Set the width to 60% */
        padding-bottom: 33.75%; /* Aspect ratio for 16:9 videos, calculated as (9/16)*60 */
        height: 0;
        overflow: hidden;
        margin: 0 auto; /* Center the container */
    }
    .video-container iframe {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }
&lt;/style&gt;

&lt;div class=&quot;video-container&quot;&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;iframe width=&quot;600px&quot; src=&quot;https://www.youtube.com/embed/VN1XIlCqdOU?si=ldut7K_l5Qoa6S2W&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Some technical facts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The magnetic pattern on each connecting surface is addressed uniquely to its counterpart. These pieces will always assemble the same way.&lt;/li&gt;
  &lt;li&gt;The internal wires are soldered to the little magnets on the connecting surfaces. This was harder than it sounds because a soldering iron will &lt;a href=&quot;https://en.wikipedia.org/wiki/Curie_temperature&quot;&gt;heat up a magnet enough to demagnetize it!&lt;/a&gt; I ended up attaching each demagnetized magnet to a working magnet to get around this.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;magnacubes&quot;&gt;“Magnacubes”&lt;/h3&gt;

&lt;p&gt;Before the self-assembling circuit, I tried the same concept with ordinary cubic blocks. Here are two pictures (before and after assembly, respectively) and a video.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-5&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 70%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/self_assembly/magnacubes.JPG&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-5&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 70%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/self_assembly/magnacubes_assembled.JPG&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;40%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/self_assembly/magnacube_video.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;h3 id=&quot;instacube&quot;&gt;“Instacube”&lt;/h3&gt;

&lt;p&gt;These linked rods take on a cubic shape under the influence of gravity.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;40%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/self_assembly/instacube.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;h3 id=&quot;self-healing-magnetic-material&quot;&gt;“Self-healing” magnetic material&lt;/h3&gt;

&lt;p&gt;I designed a repeating unit with four embedded magnets on springs pointing out in cardinal directions.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; These units can be linked up in big sheets or closed 3D structures. Individual magnetic bonds will reform if they’re broken, so you can pass a thin object through the material without any lasting damage. Here are a picture of some assembled units and a video showing the “self-healing” property.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;p&gt;
				&lt;img src=&quot;/img/self_assembly/magnetic_material.JPG&quot; class=&quot;image&quot; width=&quot;100%&quot; /&gt;
			&lt;/p&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/self_assembly/magnetic_material.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;other-ideas-and-failures&quot;&gt;Other ideas and failures&lt;/h3&gt;

&lt;p&gt;I spent a lot of time exploring “self-assembly by pulled string” in which you could pull a string taut and a 3D object would pop up. This was motivated by a desire for an instantly-assemblable tent. I got some promising initial results, but ultimately it was too hard to get the tension to transmit through the whole chain with the materials and geometry I was using. I’m sure something like this could work well enough to make a cool demo.&lt;/p&gt;

&lt;p&gt;I also tried making something that’d assemble with buoyant forces when submerged in water, but didn’t get far. I’m sure that could be made to work in some capacity, too.&lt;/p&gt;

&lt;h3 id=&quot;reflections&quot;&gt;Reflections&lt;/h3&gt;

&lt;p&gt;It’s been six years since this series of projects. In that span, I’ve matured into a proper scientist. Looking back, they’re clearly immature work, but I still find most of these demos cool. I appreciate my past self’s ingenuity and initiative.&lt;/p&gt;

&lt;p&gt;Given the opportunity, I’d offer my college self the following advice on this project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Find mentorship. Try hard to work with a professor. You’ll learn much more that way, and the small sacrifice of freedom is worth it.&lt;/li&gt;
  &lt;li&gt;Choose projects that will teach you skills you want to learn, not projects that’ll lead to the cutest demos.&lt;/li&gt;
  &lt;li&gt;Document finished projects better. You’ll want nice videos when you write a blog post in six years.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most significantly, I am no longer enamored with flashy demos of the type that inspired me in college. They have undeniable aesthetic appeal, and they can certainly be technically impressive, but it’s not clear that they’re &lt;em&gt;leading&lt;/em&gt; anywhere research-wise. In that respect, they seem more like art than engineering research. I still appreciate flashy demos as art, but I’m now quite wary when they’re presented as technical progress towards some important problem.&lt;/p&gt;

&lt;!-- [^b]: See [this related xkcd](https://xkcd.com/2128/). --&gt;

&lt;!-- I think macroscopic self-assembly research (like I did here) is much more flashy than useful. This kind of work often cites the creation of nanomachines as a main motivation [^b] — as the big problem they’re trying to solve — but it’s totally unclear to me that designing macroscopic objects that magnetically assemble is really going to help get us there. It’s certainly cool and inspiring, and if we had a plausible related avenue to making nanomachines, it could be a good way to draw attention to that, but as far as I know, the nanoscience is so far from working that this motivation seems a little blustery. The same thing happens in lots of other fields — [this xkcd](https://xkcd.com/2128/) gives the classic justification for flashy robots! --&gt;

&lt;p&gt;These days, I generally want technical research to feel like it’s going to be useful in the future — that it’s providing a useful tool, or that it’s revealing some piece of a larger puzzle, or that it suggests some new path forwards. I tend to feel that research is building an enormous tree of human knowledge, and that the best new pieces have lots of open joints to connect to yet more pieces that we could imagine discovering! One of my main reflections on my college research is that, when you’re brutally honest about it, it’s unclear that it’s actually leading anywhere!&lt;/p&gt;

&lt;p&gt;I did not have this desire for utility at the start of graduate school: at that time, novelty and aesthetic appeal were probably my primary considerations, and I frankly resented the notion of doing something more like what everyone else was doing in order to have more of an impact.
I suppose I ultimately landed somewhere in the middle: ML theory has proven important enough to do impactful stuff, but also wide open enough to do creative and beautiful work.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The north-facing and south-facing magnets are “south-pole-outwards,” and the east-facing and west-facing magnets are “north-pole-outwards.” This choice is nice for making big sheets from many units. &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 03 Jul 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/self-assembly/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/self-assembly/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Gravitree update: June 2024</title>
        <description>&lt;p&gt;&lt;em&gt;This is an update to my &lt;a href=&quot;https://james-simon.github.io/blog/gravitrees/&quot;&gt;previous post&lt;/a&gt; introducing gravitrees.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For almost ten years, I’ve been making kinetic balancing sculptures I now call &lt;em&gt;gravitrees.&lt;/em&gt; They’re all designed around the same basic principle — pieces balance in an ascending stack with (usually) only one point of contact between each piece and the one below it — but there are many geometric ways to realize this principle, some of which are quite striking.&lt;/p&gt;

&lt;p&gt;This post is a gallery of new designs I’ve come up with in the past year or so. I’ll conclude with some reflections and current outlook.&lt;/p&gt;

&lt;h2 id=&quot;aspen&quot;&gt;&lt;em&gt;Aspen&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;A classic design, recently perfected.
Now comes in both regular and mini.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/gravitree_classics.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;manzanita&quot;&gt;&lt;em&gt;Manzanita&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This is now my go-to asymmetric design.
The mini version’s quite cute!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;img src=&quot;/img/gravitree_update/manzanitas.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/manzanita_mini_blue.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;	
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tyrannosaur&quot;&gt;&lt;em&gt;Tyrannosaur&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This was my first attempt to make one that extends sideways instead of up.
Most gravitrees feel like plants to most people, but this one’s more animal.
Especially when it’s on its stand, it had an overbalanced look reminiscent of a T-Rex.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/tyrannosaur.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I also made a version that climbs upwards slightly. Not sure what its name is yet. It fills space very satisfyingly.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/stegosaur.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;chordata&quot;&gt;&lt;em&gt;Chordata&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;It’s fun to try to make one with as many pieces as possible. This one held the record at 13…&lt;/p&gt;

&lt;!-- [^a] If you count carefully, you'll only find 12 in this picture. I need to reprint the last piece! --&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/chordatus.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;autogravitree&quot;&gt;&lt;em&gt;Autogravitree&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;…until this one, which has 20 pieces and was generated programmatically!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
	        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
					&lt;img src=&quot;/img/gravitree_update/autogravitree_2.jpg&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
				&lt;/div&gt;
			&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 class=&quot;toggle-header&quot; onclick=&quot;toggleContent()&quot;&gt;Click for technical details&lt;/h4&gt;
&lt;div class=&quot;toggle-content&quot;&gt;
&lt;p&gt;When designing a gravitree, a lot of the CAD time’s spent manually tweaking different part dimensions so everything balances. It’s a pretty mechanical process, though, so I’d wanted to do it automatically for a while.

To get there, I scripted a single piece with variable dimensions in &lt;a href=&quot;https://cadquery.readthedocs.io/en/latest/index.html&quot;&gt;CadQuery&lt;/a&gt;, then ran a Python script to generate a 20-piece gravitree with each piece made from that same template.&lt;/p&gt;
&lt;/div&gt;
&lt;script&gt;
    function toggleContent() {
        var content = document.querySelector('.toggle-content');
        if (content.style.display === 'none' || content.style.display === '') {
            content.style.display = 'block';
        } else {
            content.style.display = 'none';
        }
    }
&lt;/script&gt;

&lt;style&gt;
    .toggle-header {
        cursor: pointer;
        background-color: #f1f1f1;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
    }
    .toggle-content {
        display: none;
        margin-top: 10px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        background-color: #f9f9f9;
    }
&lt;/style&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;monstera&quot;&gt;&lt;em&gt;Monstera&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;With a five-foot span, it’s the biggest gravitree I’ve ever made. It’s lasercut wood that I woodstained.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/monstera_2.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pocket-gravitree&quot;&gt;&lt;em&gt;Pocket gravitree&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;These miniature three-part gravitrees pack flat into a frame with the footprint of a credit card.
I carry one in my wallet.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/pocket_gravitree.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gravitree-20-or-triangulum&quot;&gt;&lt;em&gt;Gravitree 2.0&lt;/em&gt; or &lt;em&gt;Triangulum&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This one might be the best I’ve ever made.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 110%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/gravitree_two.jpg&quot; style=&quot;position: absolute; top: -10%; left: -16%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;maple&quot;&gt;&lt;em&gt;Maple&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This one’s a true binary tree!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/irian_cropped.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pagoda&quot;&gt;&lt;em&gt;Pagoda&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;I visited Japan last December and loved the architecture. This gravitree is inspired by &lt;a href=&quot;https://web-japan.org/nipponia/nipponia33/images/topic/22_1.jpg&quot;&gt;pagodas&lt;/a&gt; and &lt;a href=&quot;https://savvytokyo.scdn3.secure.raxcdn.com/app/uploads/2019/08/Meiji-Jingu-Torii-Top-9-Shrines-to-Visit-in-Tokyo.jpg&quot;&gt;torii gates&lt;/a&gt;. This one was technically challenging: the pieces are so similar in size that, in order to get it all to balance, I needed to make the pieces very light but hide heavy weights inside. The structure here is balsa wood (the lightest wood), but inside hold tungsten (close to the heaviest material found on Earth). The upturned flare at the end of each member both gives space to hide the tungsten shot and mimic similar convex flares I liked in the Japanese architecture.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/pagoda_gravitree.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gravitree-rings&quot;&gt;Gravitree-rings&lt;/h2&gt;

&lt;p&gt;These silver kinetic earrings make me seriously consider getting my ears pierced.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/irian_earring.jpeg&quot; style=&quot;position: absolute; top: -10%; left: -10%; width: 120%; height: 120%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tao&quot;&gt;&lt;em&gt;Tao&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This isn’t technically a gravitree, but it’s a near cousin.
The sculpture consists of a series of concentric circles, each locked into the next and free to spin within it.
The black half of each concentric circle is slightly thicker than the white half.
As a result of this weight imbalance, the sculpture tends to spin to form a yin-yang symbol: balance emerges randomly from chaos :)&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/tao.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reflections&quot;&gt;Reflections&lt;/h2&gt;

&lt;p&gt;Upon reflection, I’m pleased with the progress I’ve made in the past two years developing new gravitrees.
With the earrings, pocket gravitree, and the wooden &lt;em&gt;Monstera,&lt;/em&gt; I pushed the boundaries of size and material, and with the &lt;em&gt;Triangulum&lt;/em&gt; and &lt;em&gt;Autogravitree&lt;/em&gt; I pushed the previous boundaries of gravitree aesthetics and design methodology.
I’m most pleased with the designs that look most different from my “traditional” balls-on-sticks appearance – really like the aesthetic of the &lt;em&gt;Triangulum&lt;/em&gt; – and it seems exciting to explore how different I can make the structure look and still have it balance.&lt;/p&gt;

&lt;p&gt;Another reflection here is that these ideas often take a long time to simmer in the back of my mind.
I regularly went many months without designing a gravitree, but I’d sometimes find that questions, hopes, designs, and problems were swimming around in the background anyways, stewing and ripening.
It’s interesting that this is the case.
Relatedly, I’d periodically have moments of inspiration where I found myself with free time and sudden excitement to make some new designs.
This is, for me, a point broadly in favor of having side goals or interests that are usually dormant or inactive: they seem to cost comparatively little total time, but a small amount of effort every so often, given only when inspired, can move them forward at a slow but steady pace.&lt;sup id=&quot;fnref:b&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:b&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;I had a pretty high batting average with new concepts during this period – most of them ultimately worked, and many worked on the first try!
That said, a few of my more ambitious ideas did fail, including a gravitree that looked like a wedding cake where each layer was a pinwheel intended to spin in an opposite direction when placed in wind.&lt;sup id=&quot;fnref:c&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:c&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
Despite the occasional failures, the exploratory ideas are the best part of this hobby.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;prospects-for-selling-gravitrees&quot;&gt;Prospects for selling gravitrees&lt;/h2&gt;

&lt;p&gt;People have been telling me for a few years now that I should sell gravitrees.
There’s been a real uptick in this sort of comment lately, and with these new designs, I’m starting to believe it.
I’d love for gravitrees to be cheaply buyable (and it’d certainly be nice to make some profit off them).
A few obstacles here include that&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;3D printing is expensive. Shapeways has a marketplace I can sell through, but the prices are high – including shipping, about 30 bucks for a small gravitree and 50 bucks for a large one &lt;em&gt;without my making any profit!&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;I’m not sure how much people are willing to pay for these.&lt;/li&gt;
  &lt;li&gt;Another manufacturing technique like injection molding would be cheaper, but then you’re running a whole business, with inventory and everything. I’d be curious to know how that works, but I don’t want to run something like that long-term.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A decent plan here seems to be to try to sell at a few local art fairs, gauge interest, and perhaps build an online presence.
If demand seems high enough, it could be worth looking for a business partner to handle productization.
(That seems to be what the artist behind the &lt;a href=&quot;https://kinetrika.com/&quot;&gt;Square Wave&lt;/a&gt; did.)
I’d also be happy to sell the idea to an existing company.
It seems worth getting a patent for gravitrees if they seem likely to be marketable.
Most broadly, if I move forward, seems worth reaching out to other people who have made businesses around comparable toylike products to find out how they did it.
If you have any suggestions or leads here, drop me a line!&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:b&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;While I do feel my bang-per-unit-time for gravitrees has been fairly high, I do actually wonder whether the costs are greater than I’m making them out to be. I think about gravitrees a little every day, usually while idle or doing other things, and presumably I’d be thinking about something else for much of that span, which could add up to a lot. &lt;a href=&quot;#fnref:b&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:c&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The pieces rubbed against each other and didn’t spin freely, plus I put too much faith in the chirality of the pinwheel fans to force the fan to spin in a specific direction in wind. &lt;a href=&quot;#fnref:c&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Jun 2024 02:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/gravitree-update-2024/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/gravitree-update-2024/</guid>
        
        
        <category>random</category>
        
      </item>
    
      <item>
        <title>Household microscopy</title>
        <description>&lt;style&gt;
.hover-container {
  position: relative;
  width: 100%;
}

.image {
  display: block;
  width: 100%;
  height: auto;
}

.overlay {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  right: 0;
  height: 100%;
  width: 100%;
  opacity: 0;
  transition: .1s ease;
  background-color: #000000;
}

.hover-container:hover .overlay {
  opacity: 1;
}

.text {
  color: white;
  font-size: 12px;
  position: absolute;
  top: 10%; /* Closer to the top edge */
  left: 10%; /* Closer to the left edge */
  transform: translate(-5%, -5%); /* Adjust these translate values to fine-tune the position */
  text-align: center;
}
&lt;/style&gt;

&lt;p&gt;I’ve been using a &lt;a href=&quot;https://www.amazon.com/Carson-MicroBrite-60x-120x-Lighted-Microscope/dp/B00LAX52IQ&quot;&gt;small handheld microscope&lt;/a&gt; around my house.
For such a cheap instrument, the world it reveals is truly remarkable.
I highly recommend getting one.
As you look at each of the following images, first guess what it’s a photo of, then mouse over.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/jacket_scoped.jpg&quot; style=&quot;position: absolute; top: -16%; left: -12%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/jacket.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/screen_scoped.jpg&quot; style=&quot;position: absolute; top: -15%; left: -15%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/screen.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/bread_scoped.jpg&quot; style=&quot;position: absolute; top: -28%; left: -13%; width: 140%; height: 140%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/bread.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; style=&quot;position: absolute; top: -13%; left: -13%; width: 120%; height: 120%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/whiteboard_scoped.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/whiteboard.png&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/table_scoped.jpg&quot; style=&quot;position: absolute; top: -19%; left: -19%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/table.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/magazine_scoped.jpg&quot; style=&quot;position: absolute; top: -19%; left: -15%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/magazine.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
&lt;!--         &lt;div class=&quot;col-4&quot;&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; class=&quot;image&quot;&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot;&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; class=&quot;image&quot;&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot;&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt; --&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 11 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/household-microscopy/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/household-microscopy/</guid>
        
        
        <category>fun-science</category>
        
      </item>
    
      <item>
        <title>The sixth lake</title>
        <description>&lt;p&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/boolpool_timelapse/boolpool_timelapse.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;p&gt;If you visit Tahoe’s Five Lakes and wander off-trail in just the right direction, making your way over granite scree and thin alpine topsoil, past windworn pines and views to infinity, you will reach a sixth lake.
It is perched in a high hollow, frozen and unreachable half the year, quite indifferent to the doings of man. Its shores are lined with evergreens, its face reflects the sky, and every day for thousands of years it has born witness to the drama of the High Sierra.&lt;/p&gt;

&lt;p&gt;We were just warm apes, fast and impatient creatures there for a thrill. We were interlopers, protected by our synthetic fabrics and eating our processed foods. Wrapped all around in our human comforts, it wasn’t so easy for us to really see what was there.&lt;/p&gt;

&lt;p&gt;The lake is animated endlessly by forces too big and slow for most of us to see and understand in realtime. The snow sheets drift ploddingly around the pond like tectonic plates, colliding and melting. The wind dances on the water, rippling first one region, then another, the surface revealing the streaming clouds each time it settles to placidity and scrambling them with the return of the waves, again and again. The pines, too, are duplicated in the pond, their reflections growing downwards, slowly, slowly. The sunlight glows long and white, then blazes orange and begins to fade.&lt;/p&gt;

&lt;p&gt;This drama, or one similar, repeats every day. A single glance finds an armada of powerful natural processes that shape the scene, great and grand and far beyond our control. With a long and patient look, you can start to see them do their work. And the pond bears witness, day after day, year after year.&lt;/p&gt;

&lt;p&gt;It changes you to realize this, to see the processes of nature and know their vastness and unstoppability. A deep quiet settles over you. Perhaps you see that you, too, are a phenomenon of this sort – that a few warm apes appearing and disappearing from the side of the pond isn’t so different from the play of the wind on its surface or a deer’s stopping by.&lt;/p&gt;

&lt;p&gt;It is not easy to see this. I only truly feel this now, typing on my laptop in my comfortable Berkeley home, watching this looping timelapse, letting myself fade from the observer into part of the scene. As I do, I’m reminded of some wise words recently given to me by a friend: “we’re all just here to look around.”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Noah Sailer for suggesting a timelapse.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/boolpool-timelapse/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/boolpool-timelapse/</guid>
        
        
        <category>random, personal</category>
        
      </item>
    
      <item>
        <title>Using the Laplacian to take a local average of a function</title>
        <description>&lt;p&gt;The Laplacian operator in $d$ dimensions is defined as $\nabla^2 \equiv \sum_{i=1}^d \frac{\partial^2}{\partial x_i^2}$. It’s widely used to model diffusion processes in physics — for example, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Heat_equation&quot;&gt;heat equation&lt;/a&gt;, which describes the diffusion of heat through a material, is given by $\frac{\partial f(\mathbf{x},t)}{\partial t} = \nabla^2 f(\mathbf{x}, t)$. This operator’s come up in &lt;a href=&quot;/blog/1nn-eigenframework&quot;&gt;my recent thinking about the 1NN algorithm&lt;/a&gt;: in particular, I’ve been trying to write down a linear operator that replaces a function with its local average, and I had a sense that you could probably do this with the Laplacian somehow. In thinking this through, I encountered something neat I hadn’t appreciated before: for any analytic function $f$, it holds that&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div style=&quot;border: 1px solid black; padding: 10px; display: inline-block;&quot;&gt;
$$
\left( e^{\frac{\sigma^2}{2} \nabla^2} f \right)(\mathbf x) = \mathbb{E}_{\mathbf{\boldsymbol{\delta}} \sim \mathcal{N}(0, \sigma^2 \mathbf{I}_d)}[f(\mathbf{x} + \boldsymbol{\delta})].
$$
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;That is, the (exponentiated) Laplacian of a function (LHS) is equal to its local average w.r.t. a Gaussian measure (RHS). The RHS is nonlocal, but the LHS is entirely local, so this has some spooky-action-at-a-distance vibes.&lt;/p&gt;

&lt;p&gt;Why is this the case? I’ll give two explanations in 1D, and it’ll be relatively clear how to extend it to higher dimension.&lt;/p&gt;

&lt;h2 id=&quot;argument-from-discretization-of-space&quot;&gt;Argument from discretization of space&lt;/h2&gt;

&lt;p&gt;The Laplacian can be understood intuitively as the limit of its definition on a discretized lattice as the lattice spacing goes to zero. Suppose that instead of a function over the reals, the function $f$ only takes values on the points $\epsilon \mathbb{Z}$ — that is, ${\ldots, -2\epsilon, -\epsilon, 0, \epsilon, 2\epsilon, \ldots }$ — for some small value of $\epsilon$. We could represent the &lt;em&gt;derivative&lt;/em&gt; of $f$ as&lt;/p&gt;

\[(Df)(x) = \frac{f(x + \epsilon) - f(x)}{\epsilon},\]

&lt;p&gt;where $x \in \epsilon \mathbb{Z}$. Similarly, we can define the Laplacian as&lt;/p&gt;

\[\left( \nabla^2 f \right)(x) = \frac{f(x - \epsilon) - 2 f(x) + f(x + \epsilon)}{\epsilon^2}.\]

&lt;p&gt;If we add the identity to the Laplacian operator, we see that&lt;/p&gt;

\[\left( \left[1 + \frac{\epsilon^2}{4} \nabla^2 \right] f \right)(x) = \frac{f(x - \epsilon) + 2 f(x) + f(x + \epsilon)}{4}.\]

&lt;p&gt;(The choice of $\frac{1}{4}$ as the prefactor here is arbitrary, but will make things simpler.) We see then that the operator $1 + \frac{\epsilon^2}{4} \nabla^2$ takes a weighted average of the function value at a point and its two neighbors (with weights $\frac 14, \frac 12, \frac 14$ respectively).&lt;/p&gt;

&lt;p&gt;We can see this as a single step of a random walk. Taking a dual view where instead of staying fixed at the point $x$, we follow the diffusion of the function mass that &lt;em&gt;started&lt;/em&gt; at $x$, we see that $\frac 14$ of the mass has gone one point to the left, $\frac 12$ of the mass has remained in place, and $\frac 14$ of the mass has moved one point to the right.&lt;/p&gt;

&lt;p&gt;After many steps, a random walk on an infinite lattice approaches a (discretized) Gaussian distribution by the central limit theorem. In particular, if we take $n \gg 1$ steps, the corresponding Gaussian will have a variance of $\frac {\epsilon^2 n}{2}$. If we choose $n = \frac{2 \sigma^2}{\epsilon^2}$, we get a Gaussian with variance $\sigma^2$, which gives us the RHS of the boxed equation above!&lt;/p&gt;

&lt;p&gt;As for the LHS, since we’ve iterated this operator $n$ times, it corresponds to&lt;/p&gt;

\[\left[1 + \frac{\epsilon^2}{4} \nabla^2 \right]^n = \left[1 + \frac{\epsilon^2}{4} \nabla^2 \right]^{\frac{2 \sigma^2}{\epsilon^2}}
\xrightarrow{\epsilon \rightarrow 0}
e^{\frac {\sigma^2} 2 \nabla^2}.\]

&lt;p&gt;Great! Let’s test this conclusion on the eigenfunctions of the Laplacian. Let $f_k(x) = e^{i k x}$. Then&lt;/p&gt;

\[e^{\frac {\sigma^2} 2 \nabla^2} f_k = e^{- \frac {\sigma^2 k^2} 2} f_k\]

&lt;p&gt;and also, using the standard Gaussian integral, we find that&lt;/p&gt;

\[\mathbb{E}_{\delta \sim \mathcal{N}(0, \sigma^2)}[f_k(x + \delta)] = e^{- \frac {\sigma^2 k^2} 2} f_k.\]

&lt;p&gt;Great! Actually, since the boxed relation holds for the complete Fourier basis, it’ll hold for all functions (or at least all functions that equal their Fourier series).&lt;/p&gt;

&lt;h2 id=&quot;argument-from-taylor-series&quot;&gt;Argument from Taylor series&lt;/h2&gt;

&lt;p&gt;Consider the function $f(x) = x^a$ for some $a \in \mathbb{Z}^+$. A standard Gaussian integral yields that&lt;/p&gt;

\[\mathbb{E}_{\delta \sim \mathcal{N}(0,\sigma^2)}[\delta^a] =
\left\{\begin{array}{ll}        \frac{a!}{2^{a/2} (a/2)!} \sigma^a &amp;amp; \text{for } a \text{ even}, \\        0 &amp;amp; \text{for } a \text{ odd}.        \end{array}\right.\]

&lt;p&gt;Similarly, the LHS of the boxed equation gives the same result — this is easiest to show starting by writing out&lt;/p&gt;

\[e^{\frac{\sigma^2}{2} \nabla^2} = \lim_{n \rightarrow \infty} \left[1 + \frac{\sigma^2}{2n} \nabla^2 f \right]^n\]

&lt;p&gt;and then expanding the right hand side. Anyways, the fact that the boxed equation holds for any monomial around zero is sufficient to argue that any function that converges to its Taylor series (that is, any analytic function) satisfies the boxed equation. Neat!&lt;/p&gt;

&lt;p&gt;As a closing thought, there’s a potential paradox raised by the boxed equation, which is: how can you take a &lt;em&gt;nonlocal&lt;/em&gt; average of a function with the Laplacian, which is a local operator?
The answer is that the exponentiation actually means that we’re applying the Laplacian an infinite number of times – it’s rather more believable that this counteracts the locality of the operator, especially in light of our discretized model.&lt;/p&gt;

&lt;p&gt;Actually, one more closing thought: so the boxed equation tells us how to study the local &lt;em&gt;Gaussian&lt;/em&gt; average… what if we wanted, say, the local &lt;em&gt;Laplacian&lt;/em&gt; average, or some other rotation-invariant distribution?
Well, you could just represent that distribution in the basis of Gaussians of different widths, and then you’ve got it – you’ll just have some sum or integral over different values of \(\sigma^2\) on the LHS of the boxed equation.
That seems useful because I actually needed a Laplacian average for the 1NN analysis.&lt;/p&gt;

</description>
        <pubDate>Thu, 06 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/the-laplacian-and-diffusion/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/the-laplacian-and-diffusion/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>An eigenframework for the generalization of 1NN</title>
        <description>&lt;p&gt;In this blogpost, I’ll present an eigenframework giving the generalization of the nearest-neighbor algorithm (1NN) on two simple domains — the unit circle and the 2-torus — and discuss the prospects for a general theory.&lt;/p&gt;

&lt;h2 id=&quot;why-1nn&quot;&gt;Why 1NN?&lt;/h2&gt;

&lt;p&gt;I think 1NN is a good candidate for &lt;a href=&quot;/blog/lets-solve-learning-rules&quot;&gt;“solving” in the omniscient sense&lt;/a&gt; because it’s relatively simple, and it’s also a &lt;em&gt;linear learning rule&lt;/em&gt; in the sense that, condition on a dataset, the predicted function $\hat{f}$ is a linear function of the true function $f$. This means that we might expect a nice eigenframework to work for MSE.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;1nn-on-the-unit-circle-aka-the-1-torus&quot;&gt;1NN on the unit circle (aka the 1-torus)&lt;/h2&gt;

&lt;p&gt;The setting here will be pretty natural: we have some target function $f: [0,1) \rightarrow \mathbb{R}$ we wish to learn, we draw $n$ samples \(\{x_i\}_{i=1}^n\) from $U[0,1)$ and obtain noisy function evaluations $y_i = f(x_i) + \mathcal{N}(0, \epsilon^2)$, and then on each test point $x$ predict $y_{i(x)}$ where $i(x)$ is the index of the closest point to $x$, with circular boundary conditions on the domain. Here’s what it looks like to learn, say, a triangle wave with 20 points:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/1nn_eigenframework/sawtooth_realspace_1nn_plot.png&quot; width=&quot;55%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We will describe generalization in terms of the &lt;em&gt;Fourier decomposition&lt;/em&gt; of the target function $f(x) = \sum_{k=-\infty}^{\infty} e^{2 \pi i k x} v_k,$ where ${ v_k }$ are the Fourier coefficients. In terms of the Fourier decomposition, we have that&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div style=&quot;border: 1px solid black; padding: 10px; display: inline-block;&quot;&gt;
$$
[\text{test MSE}]_\text{1D} = \sum_k \frac{2 \pi^2 k^2}{\pi^2 k^2 + n^2} \, v_k^2 + 2 \epsilon^2. 
$$
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This is the eigenframework for 1NN in 1D! The generalization of 1NN on &lt;em&gt;any&lt;/em&gt; target function in 1D is described by this equation.&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Here are some experiments that show we’ve got it right. The function $\phi_k(x)$ here is the $k$th eigenmode, and we’re using the &lt;a href=&quot;https://mathworld.wolfram.com/FourierSeriesTriangleWave.html&quot;&gt;known Fourier decomposition of the triangle wave&lt;/a&gt;.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/1nn_eigenframework/1nn_1d_learning_curves.png&quot; width=&quot;80%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;This equation can be found a few ways, but most simply you (a) argue by symmetry that the eigenmodes contribute independently to MSE and then (b) find the test MSE for a particular eigenmode, which isn’t too hard to do. I made two approximations: (1) instead of having exactly $n$ samples, I let the samples be distributed as a Poisson process (i.e., each point has an i.i.d. chance of containing a sample), and (2) I assume the domain is infinite when computing a certain integral. Neither of these matters when $n$ is moderately large.&lt;/p&gt;

&lt;p&gt;Before moving on to the 2D case, I want to pause to highlight a few cool features of this framework:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Fourier modes do not interact — no crossterms $v_j v_k$ appear in the framework. Because 1NN is a linear learning rule, it’s inevitably possible to “diagonalize” the theory in this way for a particular $n$, but the fact that it’s simultaneously diagonalizable for all $n$ is pretty cool!&lt;/li&gt;
  &lt;li&gt;Ignoring the factors of $\pi$, we see that mode $k$ is unlearned when $n \ll k$ and fully learned when $n \gg k$. This makes a lot of sense — it’s sort of a soft version of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Nyquist_frequency&quot;&gt;Nyquist frequency&lt;/a&gt; cutoff.&lt;/li&gt;
  &lt;li&gt;Things simplify a bit if, instead of using the index $k$, we write in terms of the Laplacian eigenvalues $\lambda_k = 4 \pi^2 k^2$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1nn-on-the-2-torus&quot;&gt;1NN on the 2-Torus&lt;/h2&gt;

&lt;p&gt;We now undertake the same problem, but we’re in 2D: our data is i.i.d. from $[0,1)^2$, again with circular boundary conditions. Our Fourier decomposition now looks like&lt;/p&gt;

\[f(\mathbf{x}) = \sum_{\mathbf{k} \in \mathbb{Z}^2} e^{2 \pi i \, \mathbf{k} \cdot \mathbf{x}}.\]

&lt;p&gt;The same procedure as in the 1D case yields that&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div style=&quot;border: 1px solid black; padding: 10px; display: inline-block;&quot;&gt;
$$
[\text{test MSE}]_\text{2D} = \sum_\mathbf{k} \left( 2 - 2 e^{- \pi \mathbf{k}^2 / n} \right) \, v_\mathbf{k}^2 + 2 \epsilon^2. 
$$
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Here are some experiments that show that we’ve got the 2D case right, too.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/1nn_eigenframework/1nn_2d_learning_curves.png&quot; width=&quot;80%&quot; /&gt;
&lt;/p&gt;

&lt;h4 id=&quot;can-you-extend-these-to-k-nearest-neighbors-instead-of-just-one&quot;&gt;Can you extend these to k nearest neighbors instead of just one?&lt;/h4&gt;

&lt;p&gt;Probably! I haven’t tried, though.&lt;/p&gt;

&lt;h2 id=&quot;can-we-find-a-general-theory&quot;&gt;Can we find a general theory?&lt;/h2&gt;

&lt;p&gt;The most remarkable feature of the eigenframework for linear regression is that one set of equations works for every distribution. Can we find that here?&lt;/p&gt;

&lt;p&gt;I’m not sure. At first blush, the 1D and 2D equations look pretty different — if we were in search of some master equation, we’d almost certainly want it to unify those two cases, but the functional forms look pretty different! I suspect it might be possible, though — the linear regression eigenframework requires solving an implicit equation that depends on all the eigenvalues and can yield pretty different-looking final expressions for different spectra, so it’s believable to me that there’s some common thread here.&lt;/p&gt;

&lt;p&gt;A big question in the search for a general eigenframework is: what’s the right notion of &lt;em&gt;eigenfunction?&lt;/em&gt; In these highly symmetric domains, it’s easy — the Fourier modes are the eigenfunctions of any translation-invariant operator we might choose. In general, though, I don’t know what operator we want to diagonalize, or how to use its eigenvalues. This puzzles me. I don’t know the answer! So strange.&lt;/p&gt;

&lt;p&gt;Even without a general theory, though, I think it’d be really interesting just to continue this chain of special cases up to the arbitrary $d$-torus! I got stuck at $d=2,$ but I’d bet it can be done. Then we could think about how 1NN differs from kernel regression in high dimensions!&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; My understanding is that 1NN is worse, but I don’t actually know any quantification of this. (If you know one, drop me a line!)&lt;/p&gt;

&lt;p&gt;So that’s where things stand: these two special cases serve as proof of principle that there &lt;em&gt;might&lt;/em&gt; be a general eigenframework for 1NN… and if that exists, it’d be a cool proof of principle that more learning rules than linear regression can be “solved.” Seems like a neat problem! If I make much more progress on it, maybe I’ll write up a little paper. Let me know if you have thoughts or want to collaborate.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Intriguingly, the fact that it’s linear also means that 1NN exactly satisfies the &lt;a href=&quot;https://arxiv.org/abs/2110.03922&quot;&gt;“conservation of learnability” condition&lt;/a&gt; obeyed by linear and kernel regression, which means that you can ask questions about how these two different algorithms allocate their budget of learnability differently. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Our Fourier decomposition is easily adapted to nonuniform data distros on our domain.] In order to understand the generalization of 1NN on a target function, it suffices to compute its Fourier transform and stick the result into this equation. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This is particularly interesting because it could let us get at a puzzle posed by Misha Belkin &lt;a href=&quot;https://arxiv.org/abs/2105.14368&quot;&gt;here&lt;/a&gt; of why &lt;em&gt;inverse&lt;/em&gt; methods like KRR outperform &lt;em&gt;direct&lt;/em&gt; methods like kNN and kernel smoothing in high dimensions. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Jun 2024 02:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/1nn-eigenframework/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/1nn-eigenframework/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Let's solve more learning rules</title>
        <description>&lt;p&gt;&lt;em&gt;TLDR: the field now has an “omniscient solution” for the generalization of linear regression. We should try to find comparable solutions for other simple learning rules, like k-nearest-neighbors and kernel smoothing!
This post is motivation for &lt;a href=&quot;/blog/1nn-eigenframework&quot;&gt;part two&lt;/a&gt;, where I give a partial omniscient solution to the nearest-neighbor algorithm.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;intro-what-does-it-mean-to-solve-a-learning-rule&quot;&gt;Intro: what does it mean to “solve” a learning rule?&lt;/h2&gt;

&lt;p&gt;Essentially all of machine learning theory aims to understand the performance and behavior of different schemes for making predictions on unseen data. This is often very difficult. Given the amount of effort expended in this direction, it’s worth stepping back and asking what we’re ultimately trying to do here — that is, how will we know when we’re done?&lt;/p&gt;

&lt;p&gt;To me, one gold-standard answer is the following: &lt;strong&gt;for each learning rule under study, we want a simple set of equations that tells us how well the learning rule will perform&lt;/strong&gt; in terms of the task eigenstructure and number of samples $n$&lt;strong&gt;.&lt;/strong&gt; This isn’t the only thing we might want, but it’s clearly a powerful milestone: you could use such a theory to work out when the algorithm will perform well or poorly, and in order to derive the theory you’d have to understand a lot about the behavior of the learning rule. Viewing each learning rule as presenting a puzzle for theorists, I’d consider the development of such a theory as tantamount to “solving” the learning rule.&lt;/p&gt;

&lt;p&gt;An important clarification is that this is an “omniscient” solution in the sense that you assume complete and exact knowledge of the training task. This isn’t very useful by itself as a practical tool, but it is very useful for conceptual understanding of the learning rule (e.g. for characterizing its inductive bias). In light of this, to be more precise, we’ll say that this sort of theory is an “omniscient solution” for a learning rule.&lt;/p&gt;

&lt;p&gt;In my view, one of the most significant recent developments in machine learning theory is that &lt;em&gt;we have an omniscient solution for linear regression!&lt;/em&gt; That is, thanks to &lt;a href=&quot;https://papers.nips.cc/paper_files/paper/2001/hash/d68a18275455ae3eaa2c291eebb46e6d-Abstract.html&quot;&gt;lots&lt;/a&gt; &lt;a href=&quot;https://www.arxiv.org/abs/2002.02561&quot;&gt;and&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2006.09796&quot;&gt;lots&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2210.08571&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://proceedings.neurips.cc/paper/2021/file/9704a4fc48ae88598dcbdcdf57f3fdef-Paper.pdf&quot;&gt;recent&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1903.08560&quot;&gt;papers&lt;/a&gt;, we now have a simple set of closed-form equations that accurately predict the test performance of linear regression in terms of the task eigenstructure.&lt;/p&gt;

&lt;p&gt;Here’s some flavor for how this theory looks. First, we define an orthonormal basis of functions ${ \phi_k }$ over the input space. (In the case of linear regression, these are linear functions and are the principal directions of the feature covariance matrix.) We then decompose the target function $f$ into this basis as&lt;/p&gt;

\[f(x) = \sum_k v_k \phi_k(x)\]

&lt;p&gt;where ${ v_k }$ are the eigencoefficients. (Noise may also be included, but I omit it here for simplicity.) The eigenframework then takes the form&lt;/p&gt;

\[\text{test MSE} = \sum_k g(n, k)  \, v_k^2,\]

&lt;p&gt;where $g(n,k)$ tells you what fraction of the signal in mode $k$ contributes to test error at $n$ samples. (The function $g(n,k)$ typically decreases to zero as $n$ grows.)&lt;/p&gt;

&lt;p&gt;Here are some remarkable facts about this eigenframework:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It gives accurate predictions of test MSE even on real data!&lt;/li&gt;
  &lt;li&gt;The eigenmodes don’t interact! That is, there are no crossterms $v_j v_k$ in the final expression.&lt;/li&gt;
  &lt;li&gt;It’s very mathematically simple! In particular, the function $g$ isn’t too complicated, I just didn’t want to get into the details here. It’s simple enough that you can study it in various limits to really get intuition for how linear regression generalizes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;I’m a big fan of results of this type.&lt;/strong&gt; They feel like the way to make progress in this field: rather than showing every new result from square one, first we derive this simple and general eigenframework &lt;em&gt;once,&lt;/em&gt; and then can use it as a starting point to compute other quantities — error bounds, convergence rates, effects of dimensionality, effects of regularization, and more.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;This is how physics (and specifically statistical mechanics) works — when studying a complex system, you first seek a simple effective theory for the system, and then can easily ask lots of downstream questions about the &lt;em&gt;effective&lt;/em&gt; theory.&lt;/p&gt;

&lt;h2 id=&quot;call-to-action-lets-solve-more-learning-rules&quot;&gt;Call to action: &lt;em&gt;let’s solve more learning rules!&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;The above omniscient solution for linear regression has been very impactful. We should try to do this for more learning rules.&lt;/p&gt;

&lt;p&gt;Learning rules like k-nearest-neighbors (kNN), kernel smoothing, spline interpolation, decision trees, clustering, SVMs, and generalized additive models are widely used in practice, but we do not understand any of them as well as we now understand linear regression. It would be very impactful to solve any of them. Furthermore, the first three — kNN, kernel smoothing, and spline interpolation — are &lt;em&gt;linear&lt;/em&gt; learning rules in the sense that the predicted function depends linearly on the training targets (i.e., the training $y$’s), which suggests that an eigenframework of the &lt;em&gt;same&lt;/em&gt; type as that for linear regression might be possible. These last three seem simple enough that you might be able to solve them in one paper!&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;I suspect that omnisciently solving more learning rules would have a large impact — potentially a paradigm-altering impact, actually. Right now, all these learning rules are just a bag of disjoint algorithms: we don’t really understand any of them individually, and we sure don’t understand how they relate to each other. Any intuition I have about their relative performance is extremely ad-hoc — for example, kNN works best in low dimensions and at low noise, SVMs are often better in high dimensions, decision trees work well when different features have different notions of distance, and so on. &lt;strong&gt;If we understood all these learning rules in the same way as we understand linear regression, we could compare them on the same footing!&lt;/strong&gt; Instead of a bunch of ad-hoc intuitions, we could start to think of all these learning rules in one unified way. This feels like a place that machine learning ought to eventually get to.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;/blog/1nn-eigenframework&quot;&gt;part two&lt;/a&gt;, I’ll give the solution for 1NN on the unit circle and 2-torus and discuss what it might look like to solve 1NN in general!&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;To illustrate this point, &lt;a href=&quot;https://arxiv.org/abs/2207.06569&quot;&gt;here&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/2306.13185&quot;&gt;are&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2311.14646&quot;&gt;four&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2110.03922&quot;&gt;papers&lt;/a&gt; in which I’ve used this eigenframework as a starting point to easily derive other results. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Two other learning rules: obviously we’d all love to understand neural networks, but they’re still too poorly understood for a theory of generalization, I think — we need to understand more about their dynamics first. Second, random feature (RF) regression is a nice generalization of linear regression — and I derived an eigenframework for RF regression for &lt;a href=&quot;https://arxiv.org/abs/2311.14646&quot;&gt;a recent paper&lt;/a&gt; ;) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Jun 2024 01:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/lets-solve-learning-rules/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/lets-solve-learning-rules/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Ibuprofen vs. aspirin vs naproxen vs acetaminophen</title>
        <description>&lt;p&gt;Ibuprofen, aspirin, naproxen, and acetaminophen are the most common drugs for pain relief.
They’re staples of the modern pharmaceutical arsenal, and they’re in virtually every American home.
After years of not bothering to learn the difference between them, I finally sat down and did it yesterday, and I figured I’d write this as a reference.
I’ll give a bit about each drug, and then close with some bigger questions that feel interesting to me.&lt;/p&gt;

&lt;h2 id=&quot;basic-drug-facts&quot;&gt;Basic drug facts&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Ibuprofen&lt;/strong&gt; (brand names Advil, Motrin) is a “non-steroidal anti-inflammatory drug” (NSAID).
As the term suggests, it’s an anti-inflammatory drug, so it’s particularly useful for treating pain caused by inflammation, including headaches, menstrual cramps, and arthritis.
It works by temporarily binding to (and thus interfering with) “cyclooxygenase” (COX) enzymes which produce prostaglandins, which are involved in pathways for inflammation.
It was developed in the 1960s as a safer alternative to aspirin.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aspirin&lt;/strong&gt; (which apparently has no brand names) is a different NSAID.
It’s sometimes prescribed for long-term use as a means of reducing the risk of heart attacks.
It also works by binding to COX enzymes, but interesting, in the case of aspirin, this binding is permanent – it stays bound until the enzyme is destroyed!
It’s pretty old – it was developed in the late 1890s!
It’s more dangerous than ibuprofen, though, with more risk of side effects on the digestive system, which I imagine is why ibuprofen is the more common over-the-counter medication these days.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Naproxen&lt;/strong&gt; (brand name Aleve) is also an NSAID and also dates from the 1960s.
It acts very similarly to ibuprofen, but it lasts maybe 2x longer (but takes a bit longer to kick in).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acetaminophen&lt;/strong&gt; (brand name Tylenol; also called paracetamol internationally) is &lt;em&gt;not&lt;/em&gt; a NSAID.
It still affects the same pathway as NSAIDs, though, interfering with COX enzymes, and generally seems pretty similar, though &lt;a href=&quot;https://now.tufts.edu/2022/09/14/how-does-acetaminophen-work&quot;&gt;it’s still a mystery how exactly it works.&lt;/a&gt;
It has fewer side effects, &lt;em&gt;but&lt;/em&gt; seems to have much higher risks of overdose – in fact, it’s responsible for more overdoses than any other drug in the Western world!
It seems to primarily harm the liver and combine particularly poorly with alcohol.&lt;/p&gt;

&lt;p&gt;In my home growing up, there was also a small bottle of something called “excedrin.” Somewhat ridiculously, this looks to be a combination of aspirin, acetaminophen, and &lt;em&gt;caffeine&lt;/em&gt;!&lt;/p&gt;

&lt;h2 id=&quot;so-what-are-these-things-anyways&quot;&gt;So what &lt;em&gt;are&lt;/em&gt; these things anyways?&lt;/h2&gt;

&lt;p&gt;These drug facts are well and good – it’s nice to know the &lt;em&gt;effects&lt;/em&gt; of these substances – but what &lt;em&gt;are&lt;/em&gt; they?
Each substance consists of just one fairly small molecule.
Here they are – see if you can guess which is which. Answers are at the bottom of the page.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/pain_relievers/structures.png&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;I find it pretty amazing that these small molecules can have such specific effects!
The body is huge and has a truly immense number of processes going all the time, and these molecules are taken orally and presumably spread throughout most of the body, and they &lt;em&gt;don’t seem complicated enough&lt;/em&gt; to be addressed to a very specific function, and yet they specifically target one particular enzyme in one particular pathway.
It’s even more surprising to me that multiple simple molecules all do this job – though perhaps that’s just an indication that that enzyme is easily messed with.&lt;/p&gt;

&lt;p&gt;Looking at these molecular structures, I’m reminded anew of how weird and unintuitive biochemistry tends to be.
If you show me a picture of a mechanical part and tell me what it does, I can generally imagine how it might perform that role, and how a similar part might not be as good a choice for it, but I almost never have this experience looking at a biomolecule, and when I find out how the biomolecule works, it usually sounds ad hoc and overly complicated to me!
I wonder if learning some basic biochemistry would make things seem more mechanically intuitive.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;The molecules are 1) naproxen, 2) aspirin, 3) ibuprofen, and 4) acetaminophen. I have no idea how you could guess this, so congratulations if you did.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 01 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/otc-pain-relievers/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/otc-pain-relievers/</guid>
        
        
        <category>unlisted</category>
        
      </item>
    
      <item>
        <title>Geometric patterns in croplands</title>
        <description>&lt;p&gt;I’ve lived in California for five years now and have had the good fortune to roam up and down the state and see its mountains, valleys, and deserts.
As any outdoorsy Californian will know, these treks often featured long drives through the Central Valley, past wide fields of California crops: fruits, nuts, grain.
As a frequent passenger in these drives, I’ve come to look forward to gazing out a changing windowful of cropland, particularly when it makes a certain sort of geometric pattern.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;a href=&quot;https://www.google.com/maps/@35.8815158,-119.858065,3a,75y,51.88h,81.48t/data=!3m6!1e1!3m4!1sXlBlznQpA42OVCiQcwKAEg!2e0!7i16384!8i8192?entry=ttu&quot;&gt;
		&lt;img src=&quot;/img/croprows/croprow_pic_2.jpg&quot; width=&quot;100%&quot; /&gt;
	&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;If you’re not familiar with this effect, take a minute to really examine the strip of field planted with the baby trees.
As you scan across the strip, you’ll notice places where the saplings form lines leading off into the distance.
The lines have different degrees of definition, and the gaps between the lines have different sizes in different places.
The “regions” of lines seem to have a curious fractal pattern: if you look between two neighboring line-regions, you’ll find another, smaller set of more closely spaced lines, and so on recursively.
I find it mysterious and beautiful.
For fun, you can click on the above image to be taken to the corresponding spot in Google Streetview if you want to explore it for yourself.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/cropland_with_regions.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The regions pop out to the eye even more when you’re moving! Here’s a gif of the view out my window as I drove by the same place.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/croprow_gif.gif&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;What’s going on? In this post, I’ll explain why we see these “open” directions and try to explain why the overall visual effect is so fractally.
The basic explanation of the open regions will need only some simple math used in the physics of crystals.
When we try to understand the fractally effect, we’ll encounter some cool number theory.
I’ll end with a neat numerical experiment and an open question.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-open-directions-of-an-infinite-lattice&quot;&gt;The open directions of an infinite lattice&lt;/h2&gt;

&lt;p&gt;The nature of the special directions is easily understood starting from the observation that these saplings are planted in a near-perfect rectangular grid.&lt;sup id=&quot;fnref:f&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:f&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
In such a grid, one expects the plants to leave “aisles” along the grid directions, and if one plays around with a drawing of a grid, one soon observes that the points also form narrower isles in other, off-axis directions.
See the colored “aisles” in the illustration below.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/grid_gap_illustration.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The three examples in the above illustration correspond to particular “lattice vector” – that is, vectors \((a, b)\) with integer components, with \(a, b\) “irreducible” – that is, sharing no factors greater than \(1\).&lt;sup id=&quot;fnref:q&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:q&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
It turns out that all “open directions” – that is, directions one can look without hitting (or passing arbitrarily close to) a tree – correspond to such lattice vector!&lt;/p&gt;

&lt;p&gt;The above illustration highlights the gaps between the rows of trees, but we might similarly talk about the rows of trees lying &lt;em&gt;between&lt;/em&gt; the colored rectangles.
This is the perspective taken in crystallography.
The atoms in a crystal form a regular lattice by definition, and this lattice can be decomposed into many parallel rows (or &lt;em&gt;sheets&lt;/em&gt; in 3D), and light of the appropriate frequency will scatter off these surfaces as if they were partially reflective mirrors.
This is a common experimental technique for &lt;a href=&quot;https://en.wikipedia.org/wiki/X-ray_crystallography&quot;&gt;identifying different crystals&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;which-open-directions-will-you-see&quot;&gt;Which open directions will you see?&lt;/h2&gt;

&lt;p&gt;Great – we now have a rule describing our open directions: every direction in which one can gaze unblocked off to infinity is parallel to a lattice vector \((a, b)\), where \(a, b\) are an irreducible pair of integers.
When we look out at a big field, we should thus see a total number of… *&lt;em&gt;furiously counting on fingers&lt;/em&gt;* &lt;strong&gt;infinitely many&lt;/strong&gt; open directions, one for every \((a, b)\).
Well, that doesn’t seem right, looking at our photograph above – what’s gone wrong?&lt;/p&gt;

&lt;p&gt;Three things.
First, the field in the photo above is finite, and there are some directions we don’t see that would emerge if the field were extended.
Second, our camera has finite resolution.
Third, the trees have &lt;em&gt;nonzero width&lt;/em&gt; – some lattice directions give wider “aisles” than others, and if an aisle’s narrower than the size of a tree, we won’t see it even provided an infinite field and perfect camera.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;All three of these effects point to a general conclusion: &lt;strong&gt;wider “aisles” are more visually salient.&lt;/strong&gt;
It’d thus be useful to know the “aisle width” (or equivalent the “lattice row spacing”) corresponding to a particular lattice direction.
Some quick geometry tells us that, with pointlike trees on a unit lattice, the aisle width in direction \((a, b)\) is \(w_{a,b} = \frac{1}{\sqrt{a^2 + b^2}}.\)
This gives us a satisfying ordering of lattice directions: a lattice direction \((a, b)\) is more visually salient the smaller \(\sqrt{a^2 + b^2}\) is – that is, the closer it is to the origin!
We should thus expect the directions \((0, \pm 1)\) and \((\pm 1, 0)\) to appear most visually striking, followed by \((\pm 1, \pm 1)\), then \((\pm 1, \pm 2)\) and \((\pm 2, \pm 1)\), and so on and so forth.&lt;/p&gt;

&lt;p&gt;I’ve annotated our original image with the actual lattice directions.
This is precisely what we see:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/cropland_with_regions_labeled.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Note that the different lattice directions look like they’re parallel in this image, but they actually point radially outwards from the camera at different angles.
If we had an infinite field and a camera of good enough precision, we’d expect to see open directions corresponding to all irreducible \((a, b)\) such that \(w_{a, b}\) is less than the width of one sapling.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;fancy-math-farey-sequences-and-recursive-structure&quot;&gt;Fancy math: Farey sequences and recursive structure&lt;/h2&gt;

&lt;p&gt;The math so far is pretty familiar to physicists – we’re used to thinking about lattices and lattice vectors, having seen them a hundred times in quantum courses.
As I’ve looked out at scenes like this, the thing I really wanted to understand is: &lt;em&gt;why does it look so fractal?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let me try to be more precise: the little triangles of open “aisles” in our field photograph sure give the impression of a sort of recursive structure – given two big triangles, one usually finds a medium triangle between them, and there are never two big triangles too close to each other, sort of like a compass rose:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/compass_rose.jpeg&quot; width=&quot;20%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;It very much looks to me like, if you started adding triangular regions in order of decreasing size, you’d tend to insert each new triangle closer than chance to the midpoint of its neighbors.
I actually simulated this and it’s not true – to my surprise the distribution appears to be uniform – but in my trying to understand this I did come across some cool math.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Farey_sequence&quot;&gt;Farey sequences&lt;/a&gt; are sequences of rational fractions defined in the following manner:
the Farey sequence of order \(n\) consists of all unique rational numbers in \([0,1]\) with denominator less than or equal to \(n\).
This actually maps nicely onto our problem restricted such that \(b \ge a \ge 0\), in which case the valid \(\frac{a}{b}\) are exactly the rational numbers in \([0, 1]\).
The Farey sequences have many weird properties, one of which is the following: if \(\frac{a}{b}\) and \(\frac{c}{d}\) are neighbors in a Farey sequence, then as you increase \(n\), the first element to appear between them is always \(\frac{a + c}{b + d}\).
In our problem, that means that if there are open directions at \((a, b)\) and \((c, d)\) and no bigger open direction between them, then the &lt;em&gt;biggest&lt;/em&gt; open direction between them will lie at \((a + c, b + d)\)!
For example, the biggest open direction between \((0,1)\) and \((1,0)\) is \((1,1)\), and the biggest open direction between Farey-neighbors \((3,5)\) and \((2,3)\) is \((5, 8)\).
The wiki page for the Farey sequences has all sorts of interesting recursive diagrams that fall out of this recursive structure.
(Sidebar: as of writing, I don’t understand why this property is true. I’d be happy to have someone explain it to me!)&lt;/p&gt;

&lt;p&gt;What does this tell us about the visual effect one sees when looking out at a regularly-planted field?
Well, it means that, when adding the next-biggest open region between two existing regions, it’ll tend to be placed closer to the &lt;em&gt;smaller&lt;/em&gt; of the two existing regions.
Looking back at our field photograph (esp the version annotated with arrows), this is certainly the case!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;can-apparent-openness-vs-angle-be-described-by-a-smooth-function&quot;&gt;Can “apparent openness” vs. angle be described by a smooth function?&lt;/h2&gt;

&lt;p&gt;Number theory is very beautiful, but essentially discrete in nature.
The special directions we find are pointlike: look in one &lt;em&gt;particular direction&lt;/em&gt; and you’ll see forever, but a little bit to either side and you won’t.
However, when I look out at a cropfield like this – particularly at the gif – my eye isn’t just drawn to certain points: a bigger region leading up to the point at infinity pops out to me visually.
This makes sense – in the idealized setting, if I look slightly off an infinite-sight direction, I’ll still see pretty far!
This makes me want some kind of &lt;em&gt;continuous&lt;/em&gt; function of angle that tells me, say, how far I’ll typically see when looking in that direction.
Perhaps this function is parameterized by some notion of tree diameter \(d\), and has peaks that appear at the rational angles as \(d\) decreases.&lt;/p&gt;

&lt;p&gt;I’ll say upfront that I tried for a while and didn’t come up with anything nice.
This is the open question: can one write down a nice analytical function of angle that in some sense captures “how far” one can see along angle \(\theta\) through a forest of regularly-spaced trees of diameter \(d\)?&lt;/p&gt;

&lt;p&gt;What I do have is a hacky numerical experiment and some cool plots.
I’ll use a proxy metric I can compute in Python: with trees of diameter \(d\), what’s the farthest one could possibly see in direction \(\theta\) if one stood in the optimal place?
Well, actually, I’ll use a metric that’s almost the same (in particular being infinite in the same places) but easier to compute: with pointlike trees, what’s the longest rectangle of width \(d\) that one can fit anywhere in the lattice with long side at angle \(\theta\) from an axis?&lt;/p&gt;

&lt;p&gt;Here’s a gif of the result.&lt;sup id=&quot;fnref:b&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:b&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
	&lt;img src=&quot;/img/croprows/openness_plots.gif&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;There’s a lot of cool stuff to see in this!
Most obviously, you can see the lattice directions opening up in the predicted sequence: the cardinal directions (\((1,0)\) etc.) are open at the start, and then the \((1,1)\) direction and friends open up when \(d = \frac{1}{\sqrt{2}}\), and then the \((1,2)\) directions and friends open up, and so on.
Interestingly, a direction is always a local minimum just before it opens up – when \(d\) is just larger than \(w_{a,b}\), changing angle just a little bit in either direction will let you “see” one tree further.
This is a neat one to try to understand by playing with a diagram yourself.
There also seem to be no local maxima that aren’t vertical asymptotes.
These properties give the process a sort of fractally feel: concave-up regions between vertical asymptotes get recursively split in two by new asymptotes.&lt;/p&gt;

&lt;p&gt;This is cool and all – it’s a parameterized function which gains vertical asymptotes corresponding to all the rational numbers as the parameter decreases! – but I still want a nice analytical version of this.
If you have any ideas, let me know!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;code-and-acknowledgements&quot;&gt;Code and acknowledgements&lt;/h4&gt;

&lt;p&gt;You can find my code for generating these plots &lt;a href=&quot;https://github.com/james-simon/lattice-math&quot;&gt;here&lt;/a&gt;.
Thanks to Vincent Huang for pointing me to Farey sequences.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:f&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I’m actually quite impressed that these plants are spaced regularly enough over such a large area to give such regular patterns! &lt;a href=&quot;#fnref:f&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:q&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;By this, we mean to disallow vectors like \((4, 6)\) and \((2, 0)\) where either (a) the elements are not coprime or (b) zero is paired with an integer not equal to one. &lt;a href=&quot;#fnref:q&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Noise in the placement of trees has essentially the same effect as nonzero tree width. &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:b&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Note that I’m changing the size of the trees in this animation here even though it’s really the width of an imaginary rectangle that’s changing. &lt;a href=&quot;#fnref:b&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 21 Apr 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/cropland-crystallography/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/cropland-crystallography/</guid>
        
        
        <category>fun-math, random</category>
        
      </item>
    
  </channel>
</rss>
