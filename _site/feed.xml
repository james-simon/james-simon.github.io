<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JS</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 12 Oct 2024 11:27:51 -0700</pubDate>
    <lastBuildDate>Sat, 12 Oct 2024 11:27:51 -0700</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>Infinite-width autoencoders are cursed</title>
        <description>&lt;p&gt;&lt;strong&gt;In this blogpost, I show that infinite-width neural networks with a finite-width layer in the middle are cursed: they can’t be parameterized so that they (a) train in finite time and (b) have their weight tensors undergo alignment as prescribed by $\mu$P. I conclude by describing two modifications that fix this problem.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Autoencoder? I hardly know her!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;~ Traditional San Francisco saying&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;how-do-you-width-scale-an-autoencoder&quot;&gt;How do you width-scale an autoencoder?&lt;/h2&gt;

&lt;p&gt;Autoencoders are neural networks designed to extract (comparatively) low-dimensional representations from high-dimensional data. They’re widely-used tools for dimensionality reduction, and in the form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Variational_autoencoder&quot;&gt;VAEs&lt;/a&gt;, data &lt;em&gt;generation&lt;/em&gt;. The classic autoencoder design looks like an hourglass: the input layer is the widest, subsequent layers have fewer and fewer layers until they reach a narrowest “bottleneck” layer, and then the sequence is repeated in reverse.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/inf_width_autoencoders/autoencoder_diagram.png&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;An autoencoder is usually trained with a reconstruction objective — that is, with the goal of learning the identity function $f: x \mapsto x$ on the data.&lt;/p&gt;

&lt;p&gt;Autoencoders are interesting from a scaling perspective because they represent a case where finite width is desirable, at least in one layer. They won’t learn interesting representations if every hidden layer is wide. That said, a predominant lesson from the last few years of deep learning is that, insofar as network architecture is concerned, &lt;a href=&quot;https://proceedings.mlr.press/v139/yang21c.html&quot;&gt;wider&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2203.15556&quot;&gt;is&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2303.08774&quot;&gt;always&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2311.14646&quot;&gt;better&lt;/a&gt; so long as your hyperparameters are properly tuned. In what sense will this also be true of autoencoders?&lt;/p&gt;

&lt;p&gt;Asked from another direction: &lt;em&gt;how should you take the large-width limit of an autoencoder?&lt;/em&gt; Which layers in the hourglass above do you take to be infinite width? All of them &lt;em&gt;except&lt;/em&gt; the input, bottleneck, and output? Do you preserve the hourglass taper, jumping up to a large width $N$ at the second layer but then gradually &lt;em&gt;decreasing&lt;/em&gt; width down to a constant-width bottleneck? If so, do you taper width down by a constant factor $C$ per layer so the width at layer $\ell$ is $C^{-\ell}N$? Do you take widths $N^{-\alpha(\ell)}$ with $\alpha(\ell)$ interpolating from $1 \rightarrow 0$? It’s unclear!&lt;/p&gt;

&lt;p&gt;In this blogpost, I will show that the answer is that, with the standard notion of neural network parameterization, &lt;strong&gt;you cannot.&lt;/strong&gt; There is no consistent way to take an infinite-width limit such that the net satisfies typical notions of layer alignment and feature learning. I’ll demonstrate this by examining a two-layer slice of a deep net, aiming to convey the general problem by means of this example. I’ll then give some solutions.&lt;/p&gt;

&lt;h2 id=&quot;example-a-width-one-bottleneck&quot;&gt;Example: a width-one bottleneck&lt;/h2&gt;

&lt;p&gt;Consider a deep network which has hidden width $n_k = N$ at most layers but one bottleneck layer $\ell$ with width $n_\ell = 1$. Suppose there is no nonlinearity at the bottleneck layer or adjacent layers. For the weights before and after the bottleneck, let us adopt the shorthand $\mathbf{u}^\top = \mathbf{W}_{\ell-1}$ and $\mathbf{v} = \mathbf{W}_\ell$, with $\mathbf{u}, \mathbf{v} \in \mathbb{R}^N$. Let us write $\mathbf{M} = \mathbf{v}\mathbf{u}^\top \in \mathbb{R}^{N \times N}$ for the full rank-one parameter block comprised of these two weight matrices.&lt;/p&gt;

&lt;p&gt;We will consider training these two weight matrices through several steps of SGD on a single example $x$. Let us denote the hidden vector passed into this bottleneck block by $\mathbf{h} = \mathbf{h}(x) \in \mathbb{R}^N$, denote the output of the block by $\tilde{\mathbf{h}} = \tilde{\mathbf{h}}(x) \in \mathbb{R}^N$, and denote the gradient backpropagated into this block by $\mathbf{g} = -\nabla_{\tilde{\mathbf{h}}} \mathcal{L}$, where $\mathcal{L}$ is our global loss. We will assume for simplicity that $\mathbf{h}$ and $\mathbf{g}$ do not change for these steps. Note that the parameter gradient applied to the whole matrix is $\nabla_\mathbf{M} \mathcal{L} = \mathbf{g} \mathbf{h}^\top$. The following figure illustrates our notation:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/inf_width_autoencoders/autoencoder_slice.png&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;key-feature-learning-desideratum-weight-alignment&quot;&gt;Key feature learning desideratum: weight alignment&lt;/h3&gt;

&lt;p&gt;Suppose that we have just randomly initialized the parameters $\mathbf{u}, \mathbf{v}$ and will proceed to train for several steps with fixed learning rates. Let us denote the &lt;em&gt;alignment&lt;/em&gt; between the weight vectors and their corresponding signal vectors by&lt;/p&gt;

\[\mathcal{A}_{\text{in}} = \frac{\mathbf{u}^\top \mathbf{h}}{|\!| \mathbf{u} |\!| |\!| \mathbf{h} |\!|},
\quad
\mathcal{A}_{\text{out}} = \frac{\mathbf{v}^\top \mathbf{g}}{|\!| \mathbf{v} |\!| |\!| \mathbf{g} |\!|}.\]

&lt;p&gt;At initialization, when $\mathbf{u}, \mathbf{v}$ are random vectors, we have that $\mathcal{A}_\text{in}, \mathcal{A}_\text{out} = \Theta(N^{-1/2})$.&lt;/p&gt;

&lt;p&gt;Under the precepts of $\mu$P, we desire the following two natural conditions of feature learning:&lt;/p&gt;

&lt;p style=&quot;padding: 10px; border: 2px solid black;&quot;&gt;
&lt;strong&gt;Weight alignment desideratum.&lt;/strong&gt; After $O(1)$ steps of training, we desire that $\mathcal{A}_\text{in}, \mathcal{A}_\text{out} = \Theta(1)$.
&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;No-blowup desideratum.&lt;/strong&gt; After a handful of steps of training, the norms of each weight matrix should have reached their final size, scaling wise. That is, $\frac{|\!| \mathbf{u}_{t+1} |\!|}{|\!| \mathbf{u}_t |\!|} = \Theta(1)$ and likewise for $\mathbf{v}$.
&lt;/p&gt;

&lt;p&gt;The first desideratum captures the intuitive notion that weight matrices should align to (the top singular directions of) their gradients upon proper feature learning. In conventional parlance, feature evolution is about leading-order change in the &lt;em&gt;activations&lt;/em&gt;, not the &lt;em&gt;weight tensors,&lt;/em&gt; but these are in fact two sides of the same coin, as one finds upon a &lt;a href=&quot;https://arxiv.org/abs/2310.17813&quot;&gt;spectral-norm analysis&lt;/a&gt; of deep learning. The second desideratum basically says that we don’t want things to blow up. Obviously, if we take infinite learning rates, these matrices will align just fine, but their norms won’t stabilize. It’s fine to initialize one of them to be very close to zero, but its norm should stabilize after a few steps.&lt;/p&gt;

&lt;p&gt;We’ll now see that these intuitive desiderata are &lt;em&gt;incompatible&lt;/em&gt; for training under SGD.&lt;/p&gt;

&lt;h3 id=&quot;evolution-under-sgd&quot;&gt;Evolution under SGD&lt;/h3&gt;

&lt;p&gt;Suppose we have learning rates $\eta_u$ and $\eta_v$ for $\mathbf{u},\mathbf{v}$, respectively. These vectors then see gradient updates&lt;/p&gt;

\[\delta \mathbf{u} = \eta_u \cdot \mathcal{A}_\text{out} \cdot |\!|\mathbf{h}|\!|
|\!|\mathbf{g}|\!|
|\!|\mathbf{v}|\!|
\cdot
\hat{\mathbf{h}},\]

\[\delta \mathbf{v} = \eta_v \cdot \mathcal{A}_\text{in} \cdot |\!|\mathbf{h}|\!|
|\!|\mathbf{g}|\!|
|\!|\mathbf{u}|\!|
\cdot
\hat{\mathbf{g}},\]

&lt;p&gt;where $\hat{\mathbf{h}}, \hat{\mathbf{g}}$ are unit vectors in the directions of $\mathbf{h}, \mathbf{g}$. We are free to absorb $|\!| \mathbf{h} |\!|$ and $|\!| \mathbf{g} |\!|$ into the definitions of $\eta_u, \eta_v$. More subtly, we are free to absorb the initial scales of $|\!| \mathbf{u}_0 |\!|$ and $|\!| \mathbf{v}_0 |\!|$ into the learning rates, too, and so will henceforth assume that these vectors are of the same size up to a constant factor.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

\[\delta \mathbf{u} = \tilde \eta_u \cdot \mathcal{A}_\text{out} \cdot 
|\!|\mathbf{v}|\!|
\cdot
\hat{\mathbf{h}},\]

\[\delta \mathbf{v} = \tilde \eta_v \cdot \mathcal{A}_\text{in} \cdot 
|\!|\mathbf{u}|\!|
\cdot
\hat{\mathbf{g}}.\]

&lt;p&gt;From this, we may assess the update norms as&lt;/p&gt;

\[\frac{|\!| \delta \mathbf{u} |\!|}{|\!| \mathbf{u} |\!|} = \tilde \eta_u \cdot \mathcal{A}_\text{out} \cdot 
\frac{|\!|  \mathbf{v} |\!|}{|\!| \mathbf{u} |\!|} \sim \tilde \eta_u \cdot \mathcal{A}_\text{out},\]

\[\frac{|\!| \delta \mathbf{v} |\!|}{|\!| \mathbf{v} |\!|} = \tilde \eta_v \cdot \mathcal{A}_\text{in} \cdot 
\frac{|\!|  \mathbf{u} |\!|}{|\!| \mathbf{v} |\!|} \sim \tilde \eta_v \cdot \mathcal{A}_\text{in},\]

&lt;p&gt;where we have made use of the fact that $\frac{|\!|  \mathbf{v} |\!|}{|\!| \mathbf{u} |\!|} = \Theta(1)$. We now return to our boxed desiderata. To satisfy the weight alignment desideratum, we require $\frac{|\!| \delta \mathbf{u} |\!|}{|\!| \mathbf{u} |\!|} = \Omega(1)$ and likewise for $\mathbf{v}$. To satisfy the no-blowup desideratum, we require $\frac{|\!| \delta \mathbf{u} |\!|}{|\!| \mathbf{u} |\!|} = O(1)$ and likewise for $\mathbf{v}$. Combining both, we find that $\frac{|\!| \delta \mathbf{u} |\!|}{|\!| \mathbf{u} |\!|} = \Theta(1)$ and likewise for $\mathbf{v}$.&lt;/p&gt;

&lt;p&gt;We may now observe a contradiction. After a few steps we will have that $\mathcal{A}_\text{in}, \mathcal{A}_\text{out} = \Theta(1)$, from which we may conclude that $\tilde \eta_u, \tilde \eta_v = \Theta(1)$. However, these learning rates are too small to cause alignment to begin with! At early times when the alignments are near zero, we have&lt;/p&gt;

\[\frac{d}{dt} \mathcal{A}_\text{in}
\sim \tilde{\eta}_u \cdot \mathcal{A}_\text{out} \sim \mathcal{A}_\text{out},\]

\[\frac{d}{dt} \mathcal{A}_\text{out}
\sim \tilde{\eta}_u \cdot \mathcal{A}_\text{in} \sim \mathcal{A}_\text{in}.\]

&lt;p&gt;Treating “$\sim$” as “$=$,” the solution to this coupled ODE from small initial value is&lt;/p&gt;

\[\begin{bmatrix} \mathcal{A}_\text{in} \\ \mathcal{A}_\text{out} \end{bmatrix}
\approx
e^t
\begin{bmatrix} \mathcal{A}_0 \\ \mathcal{A}_0 \end{bmatrix},\]

&lt;p&gt;where $\mathcal{A}_0 = \frac{1}{2} [\mathcal{A}_\text{in} + \mathcal{A}_\text{out} ]_{t=0}$ is the average of the initial alignments. We can now observe that, in order to grow to order unity from an initial size of $\Theta(N^{-1/2})$ requires a number of steps $T$ such that $e^T N^{-1/2} = \Theta(1)$, which implies that $T \sim \log N$! As $N$ grows, it takes longer and more and more steps to reach alignment.&lt;/p&gt;

&lt;h3 id=&quot;what-intuitively-is-going-on&quot;&gt;What, intuitively, is going on?&lt;/h3&gt;

&lt;p&gt;The crux of the problem here is that &lt;em&gt;each weight tensor’s gradient is mediated by the other weight tensor’s alignment.&lt;/em&gt; The more aligned one tensor is, the bigger an update the other one will see. The problem is that since both alignments start small, the dynamics are a classic case of two small variables suppressing each other’s gradients!&lt;sup id=&quot;fnref:c&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:c&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; We’re stuck with a Catch-22: we could jack up the learning rates to have huge updates at the start that overcome the tiny init, but then our dynamics at late times blow up! However, if the learning rate is small enough so the dynamics at late time don’t blow up, then the dynamics take a long time to get going.&lt;sup id=&quot;fnref:b&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:b&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;a-simulation&quot;&gt;A simulation&lt;/h3&gt;

&lt;p&gt;Below is a sweep of SGD trajectories for the loss $\mathcal{L} = (\mathbf{h}^\top \mathbf{u} \mathbf{v}^\top \mathbf{g} - 1)^2$. I have taken $|\!| \mathbf{h} |\!| = |\!| \mathbf{g} |\!| = 1$ and initialized with $u_i, v_i \sim N^{-1/2}$, because any larger init will not have aligned at convergence, and any smaller init will still suffer from the core problem but worse. I train both vectors with a learning rate $\eta$ and vary $N$. I train for a fixed number of steps $T = 10$.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/inf_width_autoencoders/autoencoder_sweep.png&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;One can clearly see that the region of optimizability is shrinking, albeit slowly, with $\eta_\text{min} \sim \log N$ and $\eta_\text{max} \sim 1$ bound to converge at sufficiently large $N.$ A Colab notebook reproducing this experiment may be found &lt;a href=&quot;https://colab.research.google.com/drive/1zt6qRlnDKgxzbc95\_bE8e3ptJq4A6LZs?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;so-what-requiring-log-n-time-isnt-so-bad&quot;&gt;So what? Requiring $\log N$ time isn’t so bad.&lt;/h3&gt;

&lt;p&gt;That’s true. The two reasons to care are that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;In our theoretical models, we want to work at truly infinite width, and the logarithmic factor still blows up.&lt;/li&gt;
  &lt;li&gt;Hyperparameter transfer ($\mu$Transfer) probably won’t work because the infinite-width process isn’t well-defined.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So there you have it. Infinite-width networks with finite-width bottlenecks are cursed and can’t be  trained in a traditional fashion so all layers align to their gradients. The above argument can be extended to bottlenecks with finite width $k &amp;gt; 1$, and even to those with any width $k = o(N)$, though that’d require some random matrix theory to see.&lt;/p&gt;

&lt;p&gt;This was actually an awkward point that came up during the writing of “&lt;a href=&quot;https://arxiv.org/abs/2310.17813&quot;&gt;A Spectral Condition for Feature Learning&lt;/a&gt;.” We never resolved it, we just didn’t discuss it! It’s fine for most architectures, but it does feel like a lingering problem with $\mu$P. What is to be done?&lt;/p&gt;

&lt;h2 id=&quot;two-possible-solutions-rank-regularization-and-cascading-init&quot;&gt;Two possible solutions: rank regularization and cascading init&lt;/h2&gt;

&lt;p&gt;Here I’ll pitch two solutions that I think can be used to width-scale autoencoders.&lt;/p&gt;

&lt;p&gt;The first is to ditch the variation in width between layers — just keep everything width-$N$ — and instead enforce the rank constraints implicitly with regularization. For example, if a layer is intended to have fan-out dimension $k$, one could gradually turn on an $\ell_1$ regularization on all but the top $k$ singular vectors of the weight matrix until the regularization is so high that it becomes sparse. I believe this is consistent even at infinite width, though it does unfortunately require computing the SVD lots of times.&lt;/p&gt;

&lt;p&gt;The second idea is to do a “cascading init” in the following fashion. First, initialize all weight tensors to zero. Next, choose a random batch of perhaps $P = 10^3$ inputs. Then, starting from the start of the network and working forwards, initialize each weight tensor so that its “input” singular subspace aligns with the top PCA directions of this input batch. I believe that this, too, makes sense even at infinite width, it doesn’t require computing lots of SVDs throughout training, and it gives you a nice network with aligned vectors right from the get-go. Having everything aligned like this makes the theory really nice, and $\mu$P can be very simply expressed in spectral language.&lt;/p&gt;

&lt;p&gt;A third possibility is that batchnorm or layernorm somehow fix this. My intuition’s that they won’t, though I don’t have a solid argument.&lt;/p&gt;

&lt;p&gt;A fourth solution is to use Adam or another optimizer where the update sizes are independent of the magnitude of the gradient. I think this actually just works, but it still seems like things ought to be possible with SGD.&lt;/p&gt;

&lt;h2 id=&quot;discussion-what-now&quot;&gt;Discussion: what now?&lt;/h2&gt;

&lt;p&gt;Based on the above argument, I’m of the opinion that&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mu$P for networks of greatly-varying width (like autoencoders) is broken: there’s no way to parameterize to get proper feature learning.&lt;/li&gt;
  &lt;li&gt;There should be a unifying solution, and it’s likely to simplify $\mu$P in the process.&lt;/li&gt;
  &lt;li&gt;“Cascading init” in particular seems like it might work.&lt;/li&gt;
  &lt;li&gt;A good metric of success would be achieving hyperparameter transfer when width-scaling an autoencoder.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seems like a good project for an ambitious grad student :)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;The ideas in this blogpost were born from research discussions with Greg Yang and Jeremy Bernstein. Thanks to Blake Bordelon for recent helpful discussion.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;To see this, note that $(\mathbf{u} \rightarrow \alpha \mathbf{u}, \ \eta_u \rightarrow \alpha \eta_u, \ \eta_v \rightarrow \alpha^{-1} \eta_v)$ is an exact symmetry of the dynamics, with a similar symmetry for \(\mathbf{v}\). &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:c&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For example, consider optimizing $\mathcal{L}(x, y) = (1 - xy)^2$ for scalars $x, y$. When $x, y$ are initialized very close to zero, these dynamics will take a logarithmically-long time to get going, because each parameter suppresses the other’s gradient. &lt;a href=&quot;#fnref:c&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:b&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This is also the story with neural network dynamics in the ultra-rich regime as we describe &lt;a href=&quot;https://arxiv.org/abs/2410.04642&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;#fnref:b&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 08 Oct 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/autoencoders-are-cursed/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/autoencoders-are-cursed/</guid>
        
        
        <category>deep learning, research</category>
        
      </item>
    
      <item>
        <title>It's hard to turn a low-rank matrix into a high-rank matrix</title>
        <description>&lt;p&gt;&lt;strong&gt;&lt;em&gt;In this blogpost, I point out that applying a nonlinear function to a low-rank random matrix cannot make it into a high-rank matrix.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Large random matrices can often be profitably understood in terms of their singular value spectrum. One useful distinction is between &lt;em&gt;high (effective) rank&lt;/em&gt; and &lt;em&gt;low (effective) rank&lt;/em&gt; matrices. Low-rank matrix effects are important in deep learning, and if you listen to the whispers of deep learning theorists, they’re cropping up on the margins everywhere. My money’s on their assuming a central role in our understanding of deep learning in the coming years.&lt;/p&gt;

&lt;p&gt;This blogpost conveys a particular idea about low-rank matrices: it’s really hard to deterministically transform them into high-rank matrices. It’s written mostly for myself, but hopefully it’s useful to others.&lt;/p&gt;

&lt;h2 id=&quot;trying-and-failing-to-turn-a-low-rank-matrix-high-rank&quot;&gt;Trying and failing to turn a low-rank matrix high-rank&lt;/h2&gt;

&lt;p&gt;Suppose we independently sample two random vectors $\mathbf{x}, \mathbf{y} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_n)$ with dimension $n$ and standard Gaussian entries. From these vectors, we can construct the rank-one matrix $\mathbf{A} = \frac{1}{n} \mathbf{x}\mathbf{y}^\top$. The matrix $\mathbf{A}$ will have one nonzero singular value with value approaching $\sigma_1 = 1$ as $n$ grows.&lt;/p&gt;

&lt;p&gt;Suppose we want to turn this low-rank matrix into a high-rank matrix, with many singular values of the same order as the largest. Suppose we must accomplish this via some simple transformation, but we have no access to additional randomness, so it’s got to be a deterministic function. The most basic thing we might try is to choose some nonlinear function $\phi: \mathbb{R} \rightarrow \mathbb{R}$ and apply it elementwise to each matrix entry to get $\mathbf{A}_\phi = \frac{1}{n} \phi \circ (\mathbf{x}\mathbf{y}^\top)$.&lt;/p&gt;

&lt;p&gt;This seems promising! Having rank one is a very fragile condition, and so we expect that almost any such nonlinearity would break that condition and give us a matrix with a singular spectrum more like that of a full-rank matrix.&lt;/p&gt;

&lt;p&gt;Well, let’s try it. Here are some examples:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/low_rank_matrices/low_rank_exps_a.png&quot; width=&quot;80%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;In the top left plot, I’ve shown the singular spectrum of a rank-one matrix for three values of $n$. In the next four plots, I show the singular spectrum of matrices $\mathbf{A}_\phi$ for various $\phi$. In the final plot, I show the spectrum of a full-rank random matrix with i.i.d. entries, again for various $n$.&lt;/p&gt;

&lt;p&gt;What’s happened? None of the matrices $\mathbf{A}_\phi$ are still rank-one (well, except for $\phi: z \mapsto z^2$), but they seem to only have a handful of singular values of order unity. (They’re actually all nonzero, but they decay really fast.) Their spectra don’t look anything like the singular spectra of the full-rank matrix, which for large $n$ have many eigenvalues close to $\sigma_1$.&lt;/p&gt;

&lt;p&gt;One way to characterize this difference is through the &lt;em&gt;effective rank&lt;/em&gt; of the matrix, defined for a matrix $\mathbf{M}$ as $\text{erank}(\mathbf{M}) = \frac{(\sum_i \sigma_i(\mathbf{M}))^2}{\sum_i \sigma_i^2(\mathbf{M})}$. Here I will plot the effective rank of these same matrices as $n$ increases:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/low_rank_matrices/low_rank_exps_b.png&quot; width=&quot;80%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We see clearly that the effective rank quickly stabilizes at an order-unity value in each case, while the effective rank of a dense random matrix grows proportionally to $n$. What’s going on?&lt;/p&gt;

&lt;h2 id=&quot;the-explanation-constructing-the-singular-spectrum&quot;&gt;The explanation: constructing the singular spectrum&lt;/h2&gt;

&lt;p&gt;We will now explain what’s going on. Remarkably, we can understand this by explicitly constructing the singular vectors for large $n$.&lt;/p&gt;

&lt;h3 id=&quot;warmup-the-square-function&quot;&gt;Warmup: the square function&lt;/h3&gt;

&lt;p&gt;We’ll start with the case of the square function, which seems like the easiest. For ease of explanation, let’s give it the notation $\xi: z \mapsto z^2$.&lt;/p&gt;

&lt;p&gt;The left- and right- singular vectors of $\mathbf{A} = \frac{1}{n} \mathbf{x}\mathbf{y}^\top$ are (proportional to) $\mathbf{x}$ and $\mathbf{y}$, respectively. What about the matrix  $\mathbf{A}_\xi = \frac{1}{n} \xi \circ \mathbf{x}\mathbf{y}^\top$? Well, this matrix has entries $A_{\xi;i,j} = \frac{1}{n} x_i^2 y_j^2$, from which we can see that&lt;/p&gt;

\[\mathbf{A}_\xi = \frac{1}{n} \left( \xi \circ \mathbf{x} \right)\left( \xi \circ \mathbf{y} \right)^\top.\]

&lt;p&gt;That is, because $\xi$ has the special property that $\xi(ab) = \xi(a) \cdot \xi(b)$, the resulting matrix $\mathbf{A}_\xi$ is actually still rank-one, and its singular vectors are pointwise-nonlinearly transformed versions of the originals. This is also true for many other common functions, including $\phi \in {\mathrm{sign}, \mathrm{abs}}$ and indeed any monomial. It’s worth noting that the condition for preserving rank-one-ness is actually just that $\xi(ab) = f(a) \cdot g(b)$ for some functions $f, g$; these functions need not equal $\xi$.&lt;/p&gt;

&lt;h3 id=&quot;the-general-case&quot;&gt;The general case&lt;/h3&gt;

&lt;p&gt;To get the case of general $\phi$, we’ll actually consider an even &lt;em&gt;larger&lt;/em&gt; set of matrices: matrices $\mathbf{H}$ such that $H_{ij} = \frac{1}{n} h(x_i, y_j)$ for a bivariate function $h : \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$. The difference is that we’re not requiring this function to have the form $h(xy)$, it can be an arbitrary bivariate function.&lt;/p&gt;

&lt;p&gt;We now have a function $h(x, y)$ and probability measures $\mu_x, \mu_y$ from which $x, y$ can each be sampled (namely, both $\mu_x, \mu_y$ are unit Gaussian). This means that we can define what I think of as the “operator SVD” of the function $h$, which means writing it in the form&lt;/p&gt;

\[h(x, y) = \sum_i \sigma_i f_i(x) g_i(y),\]

&lt;p&gt;where ${ \sigma_i }$ are nonnegative singular values indexed in nonincreasing order and the functions ${f_i}, {g_i}$ are orthonormal bases in the sense that $\mathbb{E}_{x \sim \mu_x} [f_i(x) f_j(x)] = \delta_{ij}$ and $\mathbb{E}_{y \sim \mu_y} [g_i(x) g_j(x)] = \delta_{ij}$.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;The upshot is that the first singular value of $\mathbf{A}_\phi$ will be approximately the value $\sigma_1$ obtained from the operator SVD of $h(x, y) = \phi(xy)$, and the first singular vectors are going to be approximately $f_1(\mathbf{x})$ and $g_1(\mathbf{y})$. Ditto with the second and third and so on. These generally decay fairly fast (faster than a powerlaw if $h$ is analytic, I believe), so in the examples above, you usually end up with only a handful of singular values appreciably above zero. Because this spectrum is asympotically independent of the matrix size $n$ (which merely determines the error to which one approximates it), we have order-unity effective rank. Deterministic nonlinear functions applied elementwise can’t bring a matrix from rank one to full rank!&lt;/p&gt;

&lt;p&gt;As an aside, I don’t actually know how to compute the operator SVD of a generic $h$ analytically. I’d guess there’s no general form, even for Gaussian $\mu_x, \mu_y$. However, we could approximate it numerically by taking some finite-size sample of $x, y$ and working from that, and in fact, computing the singular values of $\mathbf{A}_\phi$ is precisely computing a Monte Carlo estimate of the operator singular spectrum of $h$, and ditto for the singular vectors.&lt;/p&gt;

&lt;h3 id=&quot;an-even-more-general-case-rank-k-inputs&quot;&gt;An even more general case: rank-$k$ inputs&lt;/h3&gt;

&lt;p&gt;Well, what if instead of our original matrix isn’t the rank-one matrix $\frac{1}{n} \mathbf{x} \mathbf{y}^\top$ but instead the rank-$k$ matrix $\frac{1}{n} \mathbf{X} \mathbf{Y}^\top$, with $\mathbf{X}, \mathbf{Y} \in \mathbb{R}^{n \times k}$ having standard Gaussian entries and $k = O_n(1)$? Well, turns out that’s fine — you can do the same argument as above, but instead of a scalar bivariate function $h(x, y)$, you end up having to consider a function of two $k$-dimensional vectors $h(\mathbf{\bar{x}}, \mathbf{\bar{y}})$, where $\mathbf{\bar{x}}, \mathbf{\bar{y}}$ represent rows of $\mathbf{X}, \mathbf{Y}$, respectively. (To see this, note that the matrix entries look like $\phi(\mathbf{\bar{x}}^\top \mathbf{\bar{y}})$, and then we’re taking a generalization like we did before.) You can then compute the operator SVD in the same way, where now e.g. $f_i : \mathbb{R}^{k} \rightarrow \mathbb{R}$ are functions of vectors, not scalars. The rest of the argument goes through the same way. This can also be extended to different types of nonlinear functions: for example, if instead of acting elementwise, $\phi$ acts jointly on $k \times k$ submatrices, this still carries through. I’d guess that basically any matrix transformation which acts locally, is blind to the global index of a local region, and is smooth will admit basically the same argument.&lt;/p&gt;

&lt;h2 id=&quot;relevance-to-deep-learning&quot;&gt;Relevance to deep learning&lt;/h2&gt;

&lt;p&gt;One reason this stuff matters is that gradient updates to matrices are low-rank, but modern optimizers (Adam, SignSGD, etc.) often don’t update in the true direction of the gradient, instead applying some kind of elementwise preconditioning. This story about the robustness of low-rankness means that even with these modern optimizers, we expect this low-rank behavior to remain pretty strongly in effect regardless of the optimizer. This is basically why conclusions about the scaling behavior for SGD at infinite width continue to apply (with appropriate modification) for Adam and other optimizers even though their updates aren’t gradient-aligned.&lt;/p&gt;

&lt;h3 id=&quot;some-questions-i-still-have&quot;&gt;Some questions I still have&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Can this be understood via some kind of “entropy” argument? It’d be very cool if something like the following could be made rigorous: &lt;em&gt;we only had a $\Theta(n)$ “amount of randomness” to begin with, but a full-rank random matrix has an “amount of randomness” scaling as $\Theta(n^2)$, so we couldn’t possibly close that gap with a deterministic function, and we need another source of randomness to do so.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;What if the rank $k$ isn’t order-unity, but it’s also not order-$n$, but instead scales like say $k \sim n^{1/2}$? Does the effective rank remain $O(k)$? Seems likely.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Thanks to Greg Yang for pointing this out to me during the development of &lt;a href=&quot;https://arxiv.org/pdf/2310.17813&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This is a super powerful and underutilized decomposition of bivariate functions! My coauthors and I used it as the basis of understanding Gaussian universality for random feature models in our paper &lt;a href=&quot;http://tinyurl.com/more-is-better&quot;&gt;More Is Better&lt;/a&gt;. &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 04 Oct 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/transforming-low-rank-matrices/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/transforming-low-rank-matrices/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Insights into GPT-2's positional encodings</title>
        <description>&lt;p&gt;&lt;em&gt;In this blogpost, I show that GPT-2’s positional encodings lie in a roughly orthogonal subspace to its token embeddings. I then show that the subsequent attention layer and MLP are sensitized to these subspaces in intuitive fashions.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I’m finally learning about transformers, and I intend to both learn the factual basics and also build up some intuition for how they work and how to think about them.
In doing so, I found I got a bit stuck when reading about &lt;a href=&quot;https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/&quot;&gt;positional encoding&lt;/a&gt;, the original scheme used to provide transformers with token position information.
In particular, I was confused as to how the positional encodings wouldn’t interfere with the token embeddings.
Messing around with GPT-2, I found the answer’s basically that they’re learned to be orthogonal, and the consequences of this can be seen in downstream weight tensors, too!
I’ll begin by framing the puzzle here, then show numerical evidence that these two types of embedding are approximately orthogonal, and finally show how this is reflected in some model weight tensors.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction-why-dont-positional-encodings-interfere-with-token-embeddings&quot;&gt;Introduction: why don’t positional encodings interfere with token embeddings?&lt;/h2&gt;

&lt;p&gt;The attention operation at the core of modern transformer models is blind to the order of the embedding sequence it takes as input.
The operation cares only about the similarity (as computed via the attention mechanism) between two token embeddings in the sequence and is blind to their absolute and relative positions in the sequence (except for the causal mask, which we’ll ignore).
This positional information is important, though, so it’s typically given to the model via &lt;em&gt;positional encodings.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Under this scheme, after the input sequence is tokenized and mapped to initial token embeddings, a unique vector representing a token’s index in the sequence is added to each embedding.
This provides token position information to the downstream model.
Mathematically, if our input is a sequence of tokens ${x_0, x_1, x_2, \ldots }$, we first apply a token embedding map $E$ to get a sequence of vectors ${E(x_0), E(x_1), E(x_2), \ldots}$ and then add positional encoding vectors ${p_i}$ to each embedding vector to get
${E(x_0) + p_0, E(x_1) + p_1, E(x_2) + p_2, \ldots}$.
The result is a sequence of embedding vectors such that each vector $e_i = E(x_i) + p_i$ is aware of both its input token $x_i$ and its index $i$.
This sequence is then passed on to the rest of the transformer.&lt;/p&gt;

&lt;p&gt;Thinking through the vector math here, the choice to simply add positional encodings to the token embeddings seems surprising.
I’d naively expect these vectors to interfere with each other!
We’d ideally like to be able to easily resolve both the token embedding and its position, but by adding the corresponding vectors, we get some superposition that sort of muddies them together.&lt;sup id=&quot;fnref:b&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:b&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
This is weird because you’d imagine the downstream circuitry will want to be able to resolve the two.&lt;/p&gt;

&lt;p&gt;This wouldn’t be a problem if the operation were vector concatenation instead of addition.
Equivalently, this wouldn’t be a problem if we were knew that the token embeddings and positional encodings lie in roughly orthogonal subspaces, so they won’t interfere.
This seemed like a reasonable enough hypothesis that I looked at GPT-2’s encoding to check, and it turns out that this is basically what’s happened — the embeddings and encodings learn to lie in roughly orthogonal subspaces!&lt;/p&gt;

&lt;h2 id=&quot;claim-positional-encodings-perp-token-embeddings&quot;&gt;Claim: [positional encodings] $\perp$ [token embeddings]&lt;/h2&gt;

&lt;p&gt;Here I will present numerical evidence that the positional encodings and token embeddings lie in roughly orthogonal subspaces.
I’ll first plot the singular values of both embedding matrices, which will show that the positional encodings concentrate in a pretty low-dim subspace, then show that this subspace is roughly orthogonal to the space of the token embeddings.&lt;/p&gt;

&lt;p&gt;Let’s fix some notation.
GPT-2 has an embedding dimension of $d_\text{model} = 768$, a vocabulary size of $d_\text{vocab} \approx 50 \times 10^3$, and a max context window of size $d_\text{context} = 1024$.
We’ll denote the token embedding matrix by $\mathbf{E} \in \mathbb{R}^{d_\text{vocab} \times d_\text{model}}$ and the positional encoding matrix by $\mathbf{P} \in \mathbb{R}^{d_\text{context} \times d_\text{model}}$.
Here are the singular values of these two matrices:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/P_and_E_svals.png&quot; width=&quot;75%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The most important observation here is that $\mathbf{P}$ has fairly low rank: it’s very well captured by its top, say, 30 singular directions.
The embeddings, by contrast, have fairly high rank: the mass of $\mathbf{E}$ is spread over many singular directions.&lt;/p&gt;

&lt;p&gt;We will now show that the top directions of the right singular subspace of $\mathbf{P}$ (which capture most of its mass) align well with the &lt;em&gt;bottom&lt;/em&gt; directions of the right singular subspace of $\mathbf{E}$, which permits them to not interfere with each other.
Let the right singular vectors of $\mathbf{E}$ be $v_j$ for $j = 1, \ldots, d_\text{model}$, and let \(\Pi^{(30)}_\mathbf{P}\) be the projector onto the top 30 right singular directions of $\mathbf{P}$. The plot below shows \(v_j^\top \Pi^{(30)}_\mathbf{P} v_j\).
This quantity lies in $[0,1]$ for each index $j$ and tells us the degree to which each &lt;em&gt;embedding&lt;/em&gt; singular direction is captured by the top singular directions of the &lt;em&gt;positional encoding&lt;/em&gt; matrix.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/tokemb_posenc_capture_plot.png&quot; width=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The large mass towards the right of the above plot shows that the top subspace of the positional encodings is well-aligned with the bottom subspace of the token embeddings.
Phrased differently, the positional encodings and token embeddings lie in roughly orthogonal subspaces, and so they won’t interfere!&lt;/p&gt;

&lt;p&gt;Curiously, the above plot also shows a small mass at the low indices.
This is strange to me, and I don’t know what to make of it.
Feel free to send me hypotheses!&lt;/p&gt;

&lt;p&gt;Here’s another, more detailed viz of the same phenomenon.
Here I simply plot the squared overlaps of the right singular vectors of $\mathbf{P}$ and $\mathbf{E}$:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/tokemb_posenc_overlap_heatmap.png&quot; width=&quot;50%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;I’ve applied a small Gaussian blur to the image in order to denoise a bit and bring out the essential feature: the large masses in the upper-right and bottom-right corners, which demonstrates that &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;top positional encoding subspace is aligned to the bottom token embedding subspace and vice versa.&lt;/strong&gt;&lt;sup id=&quot;fnref:q&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:q&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;claim-query-key-value-and-post-value-projection-weights-are-attuned-to-the-top-subspaces-of-both-mathbfp-and-mathbfe&quot;&gt;Claim: query, key, value, and “post-value projection” weights are attuned to the top subspaces of both \(\mathbf{P}\) and \(\mathbf{E}\)&lt;/h2&gt;

&lt;p&gt;We’ve shown that GPT-2’s positional encodings and token embeddings lie in roughly orthogonal subspaces.
This raises a natural question: can we see alignment to these subspaces in the weight matrices of the transformer?&lt;/p&gt;

&lt;p&gt;It turns out we can: the first-layer &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;proj&lt;/code&gt;&lt;sup id=&quot;fnref:c&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:c&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; weights are far more aligned to the top subspaces of both \(\mathbf{P}\) and \(\mathbf{E}\) than one would expect from chance.
The following big eight-panel plot which shows the squared singular value overlap between each of these four weight matrices (taken from the first attention layer) and both of these two embedding matrices.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/eight_panel_plot.png&quot; width=&quot;40%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;This plot shows that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key&lt;/code&gt; matrices are well-aligned to the very top subspace of \(\mathbf{P}\) (note the dark dot in the very top left of the top left two plots – you might have to zoom in).&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt; matrices are well-aligned to the top subspaces of \(\mathbf{E}\). The corresponding plots have large mass in the top left.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;proj&lt;/code&gt; matrix is well-aligned with \(\mathbf{P}\) and apparently anti-aligned to \(\mathbf{P}\)!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One could come up with various just-so stories here — for example, that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;proj&lt;/code&gt; matrix is spreading around positional information — but I’ll refrain. The important takeaways are that these matrices are clearly aware of these two important subspaces and that the top few positional encoding directions are used quite a lot in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;-&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key&lt;/code&gt; similary computation, which makes sense. These seem like useful things to keep in mind when, for example, trying to reverse-engineer transformer circuitry.&lt;/p&gt;

&lt;h2 id=&quot;claim-mlp-weights-perp-positional-encodings&quot;&gt;Claim: [MLP weights] $\perp$ [positional encodings]&lt;/h2&gt;

&lt;p&gt;Here I will present evidence that the fan-out weights of the first-hidden-layer MLP of GPT-2 have learned to be &lt;em&gt;sensitive&lt;/em&gt; to the top directions of the token embeddings and &lt;em&gt;insensitive&lt;/em&gt; to the top directions of the positional encodings.&lt;/p&gt;

&lt;p&gt;The plot below shows the squared overlaps between the right singular vectors of the MLP weights \(\mathbf{W}_1 \in \mathbb{R}^{d_\text{hid} \times d_\text{model}}\) (with \(d_\text{hid} = 4 d_\text{model}\)) and the positional encoding and token embedding matrices \(\mathbf{P}\) and \(\mathbf{E}\).
We see that the MLP is strongly attuned to the top token embedding directions (the first heatmap has most of its mass along the diagonal) and strongly insensitive to the positional encoding directions (the second heatmap has most of its mass along the antidiagonal).
This makes sense: the MLP basically acts the same on each token embedding, independently of its position in the sequence.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/mlp_overlap_heatmaps.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;h2 id=&quot;claim-the-positional-encoding-subspace-is-sparse&quot;&gt;Claim: the positional encoding subspace is sparse!&lt;/h2&gt;

&lt;p&gt;Since the top singular subspace of \(\mathbf{P}\) seems to be important, I decided to visualize it.
To my surprise, it’s sparse in the embedding space!&lt;/p&gt;

&lt;p&gt;Recall that \(\mathbf{P}\) has shape \([d_\text{context} \times d_\text{model}]\), with \(d_\text{context} = 1024\) and \(d_\text{model} = 784\). Let us visualize its top five singular vectors of \(\mathbf{P}\) in these two spaces.
The left singular vectors live in the context space, and the right singular vectors live in the embedding space.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/img/gpt2_pos_encs/pos_enc_top_vecs.png&quot; width=&quot;90%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;As we might guess, the top singular vectors in the context (i.e. token) space are basically sinusoids of different frequencies… but the top singular vectors in the embedding space are sparse, concentrating strongly on maybe 40 indices.
Returning to our original motivation of understanding how the positional encodings don’t interfere with the token embeddings, it seems that not only do they lie in orthogonal subspaces, they actually make use of (roughly) &lt;em&gt;disjoint sets of embedding indices!&lt;/em&gt; This is just a permutation away from the positional encodings being &lt;em&gt;appended&lt;/em&gt; to the token embeddings rather than added, which makes a lot of sense.&lt;/p&gt;

&lt;p&gt;That said, I have no idea why we get sparsification here.
I don’t know what induces it; I don’t know why the model prefers this over merely orthogonal subspaces.
Odd!
It’s a strong enough effect that I’d bet there’s a simple explanation.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This blogpost describes some purposeful poking around the singular value structure of GPT-2’s positional encoding and token embedding matrices.
The main observation – that the these two types of information lie in basically orthogonal subspaces, and this is reflected in intuitive ways in downstream weight matrices – seems pretty solid!
There are a bunch of auxiliary observations, including the sparsity of the positional encodings, that seem pretty clear but which I don’t have a good explanation for.
In any case, it seems useful to compile heuristic, broad-strokes observations like this when trying to build intuition for how transformers work.
Observations like this feel to me like puzzle pieces, and if we get enough on the table, maybe we can start fitting them together.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Chandan Singh for proofreading this post and for the discussion that led to it. A Colab notebook reproducing all experiments is &lt;a href=&quot;https://colab.research.google.com/drive/1CuNdE2BOdHMZQAoYXiAC0C21j-yRA8BR?usp=sharing&quot;&gt;here&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Two disclaimers here: first, this was written rather fast and some parts might be unclear, and second, I imagine someone out there already knows this! In either case, feel free to drop me a line. &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:b&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For example, if you don’t choose the vectors carefully, you might find that the word &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CAT&lt;/code&gt; at index &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3&lt;/code&gt; is embedded similarly to the word &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;APPLE&lt;/code&gt; at index &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6&lt;/code&gt; — or, mathematically, that $E(\text{CAT}) + p_3 \approx E(\text{APPLE}) + p_6$ — making them hard to distinguish. &lt;a href=&quot;#fnref:b&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:q&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I often bump into the problem of how to best measure or visualize the alignment of two matrices. This very info-dense SV-overlap plot is something I hadn’t tried before. I find it somewhat useful and will probably use it in the future. &lt;a href=&quot;#fnref:q&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:c&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;By this I refer to the “projection matrix” from the output of the attention operation back into the residual stream. This isn’t really a projection in any conventional sense, since it’s square – seems better thought of as simply a linear transformation – but that’s what people call it, so we’ll do so here. &lt;a href=&quot;#fnref:c&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 20 Aug 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/gpt2-positional-encs/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/gpt2-positional-encs/</guid>
        
        
        <category>deep learning, research</category>
        
      </item>
    
      <item>
        <title>Understanding fractals from iterated maps</title>
        <description>&lt;p&gt;&lt;em&gt;In this post, I give some mechanistic intuition for why and how the basins of iterated maps form fractals which I feel is usually missing from academic treatments of the subject.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;It is a remarkable fact of mathematics that simple dynamical systems can display immensely complex behavior.
The poster children of this notion are fractals generated from iterated maps.
You have likely seen the &lt;a href=&quot;https://math.hws.edu/eck/js/mandelbrot/MB.html&quot;&gt;Mandelbrot set&lt;/a&gt;, the most famous such fractal.
Here is a related &lt;em&gt;Julia set&lt;/em&gt; which is slightly simpler to define:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/julia_set.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The rule by which this stunning image is generated is remarkably simple.
This plot represents the complex plane, and each point \((x, y)\) in the image represents the complex number $z_0 = x + y i$.
For each such point $z_0$, we compute $z_1$, $z_2$, and so on using the iterated map&lt;/p&gt;

\[z_{t + 1} = f(z_{t+1}) = z_t^2 + c,\]

&lt;p&gt;where \(c \approx 0.2883 + 0.5383 i\) is a parameter I have tuned.
This either eventually blows up (with \(|z|\) getting very big) or doesn’t.
If $|z|$ blows up, the pixel at $z_0$ is colored white, and if it remains bounded, it is colored black.
The result is the stunning fractal above.
You can explore different values of $c$ — which generate surprisingly varied and wondrous Julia sets — &lt;a href=&quot;https://www.marksmath.org/visualization/julia_sets/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;where-does-all-this-detail-come-from&quot;&gt;Where does all this detail come from?&lt;/h2&gt;

&lt;p&gt;Part of the amazement of images like the above is that our dynamical process was extremely simple to define, but the resulting visualization is quite complicated — infinitely complicated, in fact, or at least infinitely detailed!
It gives me (and others, I suspect) the feeling of having somehow “gotten more out than we put in”.
It simply does not feel like this dynamical map should be complex enough to generate this fractal!&lt;/p&gt;

&lt;p&gt;The answer to this seeming paradox is that we are iterating the dynamical map many times: the level of detail results not from the complexity of the map but rather from the amount of computation we expend repeatedly applying it.
This can be beautifully illustrated by visualizing the result of applying only finitely many iterations, using shades of grey to indicate how may iterations a point takes to blow up:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/julia_set.gif&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The complexity of these fractals is built up over many iterations.&lt;/p&gt;

&lt;h2 id=&quot;why-do-you-get-a-fractal&quot;&gt;Why do you get a fractal?&lt;/h2&gt;

&lt;p&gt;There is a very basic question one can ask here that is virtually never addressed in introductory treatments of chaotic maps:&lt;sup id=&quot;fnref:c&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:c&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; why do we get a fractal?
This question is so obvious that, if you’ve already seen this stuff, it’s kind of hard to even see as legitimate: why does the “escape region” of \(f\) take the shape of a fractal?
Like, why not some other, non-self-similar shape?
Where does the fractal come from?
What property of the map $f$ is responsible for the self-similarity?&lt;/p&gt;

&lt;p&gt;The usual fact that &lt;em&gt;is&lt;/em&gt; given is that these dynamical maps are chaotic.
For example, students in a college course might compute the system’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Lyapunov_exponent&quot;&gt;Lyapunov exponent&lt;/a&gt; and see that it is positive around the boundary of the fractal, implying the system displays the sensitivity to initial conditions characteristic of chaotic dynamics.
Okay, great, it’s believable that these maps are chaotic, but where does this &lt;em&gt;fractal&lt;/em&gt; come from?
The two concepts are certainly related, but how exactly?&lt;/p&gt;

&lt;p&gt;I gnawed on this question sporadically for many years, and I finally have what feels like an intuitive understanding.
The main purpose of this blogpost is to convey that (high-level, nonrigorous) intuition.
The reason is basically that, if you run the dynamical map forwards, you will find that…&lt;/p&gt;

&lt;h3 id=&quot;distinctive-regions-of-the-fractal-get-mapped-to-larger-versions-of-themselves&quot;&gt;Distinctive regions of the fractal get mapped to larger versions of themselves&lt;/h3&gt;

&lt;p&gt;This property is easier to show than to tell.
Pick a small lobe in the above fractal — say, the little red lobe in the graphic below.
If you look around the fractal, you will be able to find lots and lots of little lobes, both bigger and smaller, that have the same shape.
Now pick your favorite point in the red lobe.
Upon the action of the map $f$, this point will generally be mapped to another point at the same position in a larger version of the same lobe!
In the diagram below, an initial point in the red lobe gets mapped to a point in the orange lobe, then the yellow lobe, then the green, and so on.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/lobe_map.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here’s the same thing with a different starting lobe:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/lobe_map_2.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;To underscore the first example, here’s an actual computer-generated plot in which the region enclosed by each colored circle is mapped to the region enclosed by the subsequent one:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/circle_map.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Note how each successive circle here is larger than the one before it, showing that the map is expansive, and the Lyapunov exponents here are positive.&lt;/p&gt;

&lt;p&gt;This behavior is enough to explain why the final Julia set contains so many versions of the same lobe.
This follows from basically an inductive argument.
I will give the argument first and then follow it up with some graphical illustration.&lt;/p&gt;

&lt;p&gt;Note first that &lt;em&gt;any point that is mapped to a black point will also be a black point&lt;/em&gt; – the two points lie on the same trajectory, so they have the same fate (to diverge or not to diverge).
As the base case, assume there is some black region with an interesting shape.
As the inductive step, now, suppose that some other, smaller volume of space gets mapped to a volume of space including this black region.
There will be a shrunken copy of the black region in this other volume — the black region has been duplicated!
Now we can run this process again and again, positing a &lt;em&gt;third,&lt;/em&gt; even smaller volume of space that maps to the second, and so on and so on.
(Fairly simple mapping functions $f(z)$ can give you an infinite sequence of volumes mapping to each other like this; note that the volumes can overlap.
We will give a toy example illustrating this soon.)
We now have an infinite number of copies of the original black region, getting ever smaller and more delicate — a fractal!&lt;/p&gt;

&lt;p&gt;This really becomes much more tangible when you play around with yourself with an eye to this behavior.
You can explore this fractal in-browser at (this nice website)[https://www.marksmath.org/visualization/julia_sets/].&lt;/p&gt;

&lt;p&gt;As a final speculation before we use this notion to make some fractals, I wonder if there’s some sense in which getting a fractal is inevitable in the Julia set of a chaotic iterated map.
Surely the set will be some chaotic, extremely complicated shape… and it vaguely seems to me like, because the generating function is some fixed function with some finite amount of information required to specify it, it couldn’t possibly result in a chaotic shape which &lt;em&gt;isn’t&lt;/em&gt; a fractal — that is, for which each lower level of detail is unlike the higher levels — because that would entail an infinite amount of information to specify.
Perhaps there are connections to computational complexity in here, where the function is fixed and has $O(1)$ complexity, but the fractal naively has “geometric complexity” $O(T)$, where $T$ is the number of iterations the map is run for, and somehow the self-similarity of the fractal lets one come up with a new notion of geometric complexity for which these Julia sets only have $O(1)$ complexity.
This would feel like a satisfying resolution to the motivating “paradox” that it felt like we were getting more out of these systems than we put in.&lt;/p&gt;

&lt;h2 id=&quot;hand-designing-some-fractals&quot;&gt;Hand-designing some fractals&lt;/h2&gt;

&lt;p&gt;If you really understand how something works, you should be able to make one yourself.
I’m claiming that the ingredients for self-similar basins of attraction from an iterated map are basically (a) expansive behavior and (b) an infinite sequence of volumes that map into each other, leading ultimately to some interesting basin boundary.
The easiest way to satisfy both (a) and (b) is perhaps to have some region $\mathcal{R}$ that maps to a larger region $\mathcal{R}’$ that contains both some basin boundary &lt;em&gt;and the original region $\mathcal{R}$ itself.&lt;/em&gt;
This pretty easily gives an infinite sequence of volumes (and a resulting fractal) because, well, the basin structure within $\mathcal{R}’$ has to contain a complete copy of itself, so self-similar structure is inevitable!&lt;/p&gt;

&lt;h3 id=&quot;first-example-circles-in-2d&quot;&gt;First example: circles in 2D&lt;/h3&gt;

&lt;p&gt;Here’s an example.
We will continue to work in the complex plane and use the map&lt;/p&gt;

\[z_{t+1} = c z_t,\]

&lt;p&gt;where $c = 2$ for now.
I will then draw a circle somewhere in the plane.
If a point $z_0$ ever lands inside the circle after some number of iterations, we decree that it may never leave, and we color the pixel at $z_0$ black.
If it never lands in the circle, the pixel at $z_0$ is white.&lt;/p&gt;

&lt;p&gt;Here’s what you get:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/circles_1.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here I have chosen the “sticky circle” (the largest circle) to have radius $0.4$, centered at $z_c = 1 + i$.
The red crosshair shows the origin.
Note that we get a fractal!&lt;/p&gt;

&lt;p&gt;We can make it more interesting if we instead add some rotation with, say, $c = 1 + 0.1 i$:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/circles_2.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;second-example-chaotic-map-in-1d&quot;&gt;Second example: chaotic map in 1D&lt;/h3&gt;

&lt;p&gt;Let’s design another one.
This one will be only 1D.
Consider the following map $z_t \mapsto z_{t+1}$:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/1d_map_one_iteration.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Try to guess what this map will do when iterated many times.
It’s not too hard to see that the points on the far left and far right will continue to flow all the way to the edges, so we have $0$ and $1$ as basins of attraction…
and I have designed the middle region so that parts of it map into these two basins (the peak and trough), and other parts &lt;em&gt;map back into the whole middle region,&lt;/em&gt; guaranteeing that any basin structure is repeated and making the basins structure self-similar.
Here’s what this map looks like after being applied seven times:&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/fractals/1d_map_iterated.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This structure is self-similar (which I verified by zooming in).&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;In this post, I’ve aimed to give some mechanistic insight into why and how the basins of attraction of iterated maps give fractals.
There’s a huge raft of technical content I could have brought in here but didn’t — if you’re interested, I’d encourage you to check out Lyapunov exponents, the logstic map, the Mandelbrot set, and perhaps Steven Strogatz’ &lt;em&gt;Nonlinear Dynamics and Chaos.&lt;/em&gt;
I had never really felt I could see the genesis of this class of fractals before, but now I can, so I hope this sheds some light for some other folks, too!&lt;/p&gt;

&lt;p&gt;A major takeaway I have here, which I didn’t fully appreciate before, is that in systems like these, chaos is usually studied as a &lt;em&gt;local&lt;/em&gt; property — e.g., the Lyapunov exponent is positive, and it’s locally defined — but these fractals are &lt;em&gt;global.&lt;/em&gt;
I think this probably explains why I hadn’t encountered a good explanation like this before: it seems hard to reduce the global property of fractal-formation to a property of the return map that’s simple enough to prove a theorem about.
I wonder if there’s some analytical condition on the return map that one could define that’d be necessary and sufficient for it to give you fractals.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:c&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This has never been addressed in the maybe five times I’ve seen this material, that is – but tell me if you know a good treatment somewhere! &lt;a href=&quot;#fnref:c&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 31 Jul 2024 12:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/fractals-in-iterated-maps/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/fractals-in-iterated-maps/</guid>
        
        
        <category>fun-science</category>
        
      </item>
    
      <item>
        <title>The time I caught an egg in my mouth</title>
        <description>&lt;!-- This one is exactly what it sounds like. --&gt;
&lt;p&gt;Of all my recent years’ varied adventures, the most memorable ten seconds might well have been when my housemate tossed me an egg and I caught it in my mouth.
The hour was 9am.
The egg was raw.
The music was high.
It was our first try.
It looked a little like this.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;80%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/eggman/EGGMAN.MP4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;p&gt;I suppose one could look for a deeper meaning here, some lesson on spontanaeity or the pursuit of the comic absurd or the value of attempting things that seem impossible, but no: this one’s just an egg, and it was awesome.
The satisfying ka-&lt;em&gt;chunk&lt;/em&gt; of the egg clinking off my teeth and lodging unbroken in my mouth like a heavy-duty mechanism locking into place stayed with me all day.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Irian D’Andrea for the grade-A toss and to Olive Eilbott for both issuing the challenge and capturing it on video.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 05 Jul 2024 01:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/egg/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/egg/</guid>
        
        
        <category>random</category>
        
      </item>
    
      <item>
        <title>Experiments in self-assembly</title>
        <description>&lt;p&gt;In 2018, I designed and prototyped a series of self-assembling objects.
I never published anything about it then, so I’m doing it now.
I’ll give background and my motivation, show some cute demos, and conclude with some reflections.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;I’ve always liked cute interactive technical projects. This was particularly true in college, during which I made lots of mostly-useless-but-fun things, including&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a laser-activated light switch&lt;/li&gt;
  &lt;li&gt;a robotic articulated necktie which could grab food and bring it to the wearer’s mouth&lt;/li&gt;
  &lt;li&gt;various 3D printed ball mazes&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://james-simon.github.io/blog/gravitrees/&quot;&gt;lots of balancing sculptures&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;and &lt;a href=&quot;vthunt.com&quot;&gt;a campus-wide puzzlehunt&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I thought self-assembling systems and other passive mechanics were particularly cool — some demos that inspired me included &lt;a href=&quot;https://www.youtube.com/watch?v=Bnj1sPfo4Ek&quot;&gt;this self-assembling “chair,”&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=6aZbJS6LZbs&quot;&gt;this swarm of cubic robots&lt;/a&gt;, and this &lt;a href=&quot;https://www.youtube.com/watch?v=ZVYz7g-qLjs&quot;&gt;robot origami&lt;/a&gt;, all from MIT. As a senior, I got a small grant from the 3D printing service Shapeways to explore 3D printed self-assembling systems.&lt;/p&gt;

&lt;p&gt;I spent a semester on the project and came up with some cool prototypes. None of them are particularly scalable or practical, but they are cute.&lt;/p&gt;

&lt;h3 id=&quot;self-assembling-circuit&quot;&gt;Self-assembling circuit&lt;/h3&gt;

&lt;p&gt;I designed a self-assembling circuit. It consists of four pieces, each of which has two magnetic surfaces to link up to its two neighbors. The four pieces are hollow and contain circuit components: a battery, a resistor, an LED, and a blank wire, respectively. When all four pieces are joined in a loop, the LED lights up. As far as I know, this is the first self-assembling circuit ever made (as long as you don’t count naturally-occurring circuits in biochemistry!).&lt;/p&gt;

&lt;p&gt;The four pieces will link up after being shaken together for a minute or two. Here’s a demo video:&lt;/p&gt;

&lt;!-- youtube embed. pretty cursed -- no idea how this is working --&gt;
&lt;style&gt;
    .video-container {
        position: relative;
        width: 60%; /* Set the width to 60% */
        padding-bottom: 33.75%; /* Aspect ratio for 16:9 videos, calculated as (9/16)*60 */
        height: 0;
        overflow: hidden;
        margin: 0 auto; /* Center the container */
    }
    .video-container iframe {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }
&lt;/style&gt;

&lt;div class=&quot;video-container&quot;&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;iframe width=&quot;600px&quot; src=&quot;https://www.youtube.com/embed/VN1XIlCqdOU?si=ldut7K_l5Qoa6S2W&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Some technical facts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The magnetic pattern on each connecting surface is addressed uniquely to its counterpart. These pieces will always assemble the same way.&lt;/li&gt;
  &lt;li&gt;The internal wires are soldered to the little magnets on the connecting surfaces. This was harder than it sounds because a soldering iron will &lt;a href=&quot;https://en.wikipedia.org/wiki/Curie_temperature&quot;&gt;heat up a magnet enough to demagnetize it!&lt;/a&gt; I ended up attaching each demagnetized magnet to a working magnet to get around this.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;magnacubes&quot;&gt;“Magnacubes”&lt;/h3&gt;

&lt;p&gt;Before the self-assembling circuit, I tried the same concept with ordinary cubic blocks. Here are two pictures (before and after assembly, respectively) and a video.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-5&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 70%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/self_assembly/magnacubes.JPG&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-5&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 70%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/self_assembly/magnacubes_assembled.JPG&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;40%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/self_assembly/magnacube_video.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;h3 id=&quot;instacube&quot;&gt;“Instacube”&lt;/h3&gt;

&lt;p&gt;These linked rods take on a cubic shape under the influence of gravity.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;40%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/self_assembly/instacube.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;h3 id=&quot;self-healing-magnetic-material&quot;&gt;“Self-healing” magnetic material&lt;/h3&gt;

&lt;p&gt;I designed a repeating unit with four embedded magnets on springs pointing out in cardinal directions.&lt;sup id=&quot;fnref:a&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:a&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; These units can be linked up in big sheets or closed 3D structures. Individual magnetic bonds will reform if they’re broken, so you can pass a thin object through the material without any lasting damage. Here are a picture of some assembled units and a video showing the “self-healing” property.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;p&gt;
				&lt;img src=&quot;/img/self_assembly/magnetic_material.JPG&quot; class=&quot;image&quot; width=&quot;100%&quot; /&gt;
			&lt;/p&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/self_assembly/magnetic_material.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;other-ideas-and-failures&quot;&gt;Other ideas and failures&lt;/h3&gt;

&lt;p&gt;I spent a lot of time exploring “self-assembly by pulled string” in which you could pull a string taut and a 3D object would pop up. This was motivated by a desire for an instantly-assemblable tent. I got some promising initial results, but ultimately it was too hard to get the tension to transmit through the whole chain with the materials and geometry I was using. I’m sure something like this could work well enough to make a cool demo.&lt;/p&gt;

&lt;p&gt;I also tried making something that’d assemble with buoyant forces when submerged in water, but didn’t get far. I’m sure that could be made to work in some capacity, too.&lt;/p&gt;

&lt;h3 id=&quot;reflections&quot;&gt;Reflections&lt;/h3&gt;

&lt;p&gt;It’s been six years since this series of projects. In that span, I’ve matured into a proper scientist. Looking back, they’re clearly immature work, but I still find most of these demos cool. I appreciate my past self’s ingenuity and initiative.&lt;/p&gt;

&lt;p&gt;Given the opportunity, I’d offer my college self the following advice on this project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Find mentorship. Try hard to work with a professor. You’ll learn much more that way, and the small sacrifice of freedom is worth it.&lt;/li&gt;
  &lt;li&gt;Choose projects that will teach you skills you want to learn, not projects that’ll lead to the cutest demos.&lt;/li&gt;
  &lt;li&gt;Document finished projects better. You’ll want nice videos when you write a blog post in six years.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most significantly, I am no longer enamored with flashy demos of the type that inspired me in college. They have undeniable aesthetic appeal, and they can certainly be technically impressive, but it’s not clear that they’re &lt;em&gt;leading&lt;/em&gt; anywhere research-wise. In that respect, they seem more like art than engineering research. I still appreciate flashy demos as art, but I’m now quite wary when they’re presented as technical progress towards some important problem.&lt;/p&gt;

&lt;!-- [^b]: See [this related xkcd](https://xkcd.com/2128/). --&gt;

&lt;!-- I think macroscopic self-assembly research (like I did here) is much more flashy than useful. This kind of work often cites the creation of nanomachines as a main motivation [^b] — as the big problem they’re trying to solve — but it’s totally unclear to me that designing macroscopic objects that magnetically assemble is really going to help get us there. It’s certainly cool and inspiring, and if we had a plausible related avenue to making nanomachines, it could be a good way to draw attention to that, but as far as I know, the nanoscience is so far from working that this motivation seems a little blustery. The same thing happens in lots of other fields — [this xkcd](https://xkcd.com/2128/) gives the classic justification for flashy robots! --&gt;

&lt;p&gt;These days, I generally want technical research to feel like it’s going to be useful in the future — that it’s providing a useful tool, or that it’s revealing some piece of a larger puzzle, or that it suggests some new path forwards. I tend to feel that research is building an enormous tree of human knowledge, and that the best new pieces have lots of open joints to connect to yet more pieces that we could imagine discovering! One of my main reflections on my college research is that, when you’re brutally honest about it, it’s unclear that it’s actually leading anywhere!&lt;/p&gt;

&lt;p&gt;I did not have this desire for utility at the start of graduate school: at that time, novelty and aesthetic appeal were probably my primary considerations, and I frankly resented the notion of doing something more like what everyone else was doing in order to have more of an impact.
I suppose I ultimately landed somewhere in the middle: ML theory has proven important enough to do impactful stuff, but also wide open enough to do creative and beautiful work.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:a&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The north-facing and south-facing magnets are “south-pole-outwards,” and the east-facing and west-facing magnets are “north-pole-outwards.” This choice is nice for making big sheets from many units. &lt;a href=&quot;#fnref:a&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 03 Jul 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/self-assembly/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/self-assembly/</guid>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Gravitree update: June 2024</title>
        <description>&lt;p&gt;&lt;em&gt;This is an update to my &lt;a href=&quot;https://james-simon.github.io/blog/gravitrees/&quot;&gt;previous post&lt;/a&gt; introducing gravitrees.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For almost ten years, I’ve been making kinetic balancing sculptures I now call &lt;em&gt;gravitrees.&lt;/em&gt; They’re all designed around the same basic principle — pieces balance in an ascending stack with (usually) only one point of contact between each piece and the one below it — but there are many geometric ways to realize this principle, some of which are quite striking.&lt;/p&gt;

&lt;p&gt;This post is a gallery of new designs I’ve come up with in the past year or so. I’ll conclude with some reflections and current outlook.&lt;/p&gt;

&lt;h2 id=&quot;aspen&quot;&gt;&lt;em&gt;Aspen&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;A classic design, recently perfected.
Now comes in both regular and mini.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/gravitree_classics.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;manzanita&quot;&gt;&lt;em&gt;Manzanita&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This is now my go-to asymmetric design.
The mini version’s quite cute!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;img src=&quot;/img/gravitree_update/manzanitas.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/manzanita_mini_blue.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;	
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tyrannosaur&quot;&gt;&lt;em&gt;Tyrannosaur&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This was my first attempt to make one that extends sideways instead of up.
Most gravitrees feel like plants to most people, but this one’s more animal.
Especially when it’s on its stand, it had an overbalanced look reminiscent of a T-Rex.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/tyrannosaur.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I also made a version that climbs upwards slightly. Not sure what its name is yet. It fills space very satisfyingly.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/stegosaur.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;chordata&quot;&gt;&lt;em&gt;Chordata&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;It’s fun to try to make one with as many pieces as possible. This one held the record at 13…&lt;/p&gt;

&lt;!-- [^a] If you count carefully, you'll only find 12 in this picture. I need to reprint the last piece! --&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/chordatus.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;autogravitree&quot;&gt;&lt;em&gt;Autogravitree&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;…until this one, which has 20 pieces and was generated programmatically!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;!-- &lt;img src=&quot;/img/gravitree_update/autogravitree_1.jpg&quot; width=&quot;100%&quot;&gt; --&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
	        	&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 130%; overflow: hidden; position: relative;&quot;&gt;
					&lt;img src=&quot;/img/gravitree_update/autogravitree_2.jpg&quot; style=&quot;position: absolute; top: 0%; left: 0%; width: 100%; height: 100%; object-fit: cover;&quot; /&gt;
				&lt;/div&gt;
			&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-2&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 class=&quot;toggle-header&quot; onclick=&quot;toggleContent()&quot;&gt;Click for technical details&lt;/h4&gt;
&lt;div class=&quot;toggle-content&quot;&gt;
&lt;p&gt;When designing a gravitree, a lot of the CAD time’s spent manually tweaking different part dimensions so everything balances. It’s a pretty mechanical process, though, so I’d wanted to do it automatically for a while.

To get there, I scripted a single piece with variable dimensions in &lt;a href=&quot;https://cadquery.readthedocs.io/en/latest/index.html&quot;&gt;CadQuery&lt;/a&gt;, then ran a Python script to generate a 20-piece gravitree with each piece made from that same template.&lt;/p&gt;
&lt;/div&gt;
&lt;script&gt;
    function toggleContent() {
        var content = document.querySelector('.toggle-content');
        if (content.style.display === 'none' || content.style.display === '') {
            content.style.display = 'block';
        } else {
            content.style.display = 'none';
        }
    }
&lt;/script&gt;

&lt;style&gt;
    .toggle-header {
        cursor: pointer;
        background-color: #f1f1f1;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
    }
    .toggle-content {
        display: none;
        margin-top: 10px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        background-color: #f9f9f9;
    }
&lt;/style&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;monstera&quot;&gt;&lt;em&gt;Monstera&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;With a five-foot span, it’s the biggest gravitree I’ve ever made. It’s lasercut wood that I woodstained.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/monstera_2.png&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pocket-gravitree&quot;&gt;&lt;em&gt;Pocket gravitree&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;These miniature three-part gravitrees pack flat into a frame with the footprint of a credit card.
I carry one in my wallet.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/pocket_gravitree.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gravitree-20-or-triangulum&quot;&gt;&lt;em&gt;Gravitree 2.0&lt;/em&gt; or &lt;em&gt;Triangulum&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This one might be the best I’ve ever made.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 110%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/gravitree_two.jpg&quot; style=&quot;position: absolute; top: -10%; left: -16%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;maple&quot;&gt;&lt;em&gt;Maple&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This one’s a true binary tree!&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/irian_cropped.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pagoda&quot;&gt;&lt;em&gt;Pagoda&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;I visited Japan last December and loved the architecture. This gravitree is inspired by &lt;a href=&quot;https://web-japan.org/nipponia/nipponia33/images/topic/22_1.jpg&quot;&gt;pagodas&lt;/a&gt; and &lt;a href=&quot;https://savvytokyo.scdn3.secure.raxcdn.com/app/uploads/2019/08/Meiji-Jingu-Torii-Top-9-Shrines-to-Visit-in-Tokyo.jpg&quot;&gt;torii gates&lt;/a&gt;. This one was technically challenging: the pieces are so similar in size that, in order to get it all to balance, I needed to make the pieces very light but hide heavy weights inside. The structure here is balsa wood (the lightest wood), but inside hold tungsten (close to the heaviest material found on Earth). The upturned flare at the end of each member both gives space to hide the tungsten shot and mimic similar convex flares I liked in the Japanese architecture.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/pagoda_gravitree.jpeg&quot; style=&quot;width: 100%&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gravitree-rings&quot;&gt;Gravitree-rings&lt;/h2&gt;

&lt;p&gt;These silver kinetic earrings make me seriously consider getting my ears pierced.&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;p style=&quot;text-align:center;&quot;&gt;
			&lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
				&lt;img src=&quot;/img/gravitree_update/irian_earring.jpeg&quot; style=&quot;position: absolute; top: -10%; left: -10%; width: 120%; height: 120%; object-fit: cover;&quot; /&gt;
			&lt;/div&gt;
			&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tao&quot;&gt;&lt;em&gt;Tao&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;This isn’t technically a gravitree, but it’s a near cousin.
The sculpture consists of a series of concentric circles, each locked into the next and free to spin within it.
The black half of each concentric circle is slightly thicker than the white half.
As a result of this weight imbalance, the sculpture tends to spin to form a yin-yang symbol: balance emerges randomly from chaos :)&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;
			&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
			    &lt;source src=&quot;/img/gravitree_update/tao.mp4&quot; type=&quot;video/mp4&quot; /&gt;
			&lt;/video&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-4&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reflections&quot;&gt;Reflections&lt;/h2&gt;

&lt;p&gt;Upon reflection, I’m pleased with the progress I’ve made in the past two years developing new gravitrees.
With the earrings, pocket gravitree, and the wooden &lt;em&gt;Monstera,&lt;/em&gt; I pushed the boundaries of size and material, and with the &lt;em&gt;Triangulum&lt;/em&gt; and &lt;em&gt;Autogravitree&lt;/em&gt; I pushed the previous boundaries of gravitree aesthetics and design methodology.
I’m most pleased with the designs that look most different from my “traditional” balls-on-sticks appearance – really like the aesthetic of the &lt;em&gt;Triangulum&lt;/em&gt; – and it seems exciting to explore how different I can make the structure look and still have it balance.&lt;/p&gt;

&lt;p&gt;Another reflection here is that these ideas often take a long time to simmer in the back of my mind.
I regularly went many months without designing a gravitree, but I’d sometimes find that questions, hopes, designs, and problems were swimming around in the background anyways, stewing and ripening.
It’s interesting that this is the case.
Relatedly, I’d periodically have moments of inspiration where I found myself with free time and sudden excitement to make some new designs.
This is, for me, a point broadly in favor of having side goals or interests that are usually dormant or inactive: they seem to cost comparatively little total time, but a small amount of effort every so often, given only when inspired, can move them forward at a slow but steady pace.&lt;sup id=&quot;fnref:b&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:b&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;I had a pretty high batting average with new concepts during this period – most of them ultimately worked, and many worked on the first try!
That said, a few of my more ambitious ideas did fail, including a gravitree that looked like a wedding cake where each layer was a pinwheel intended to spin in an opposite direction when placed in wind.&lt;sup id=&quot;fnref:c&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:c&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
Despite the occasional failures, the exploratory ideas are the best part of this hobby.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;prospects-for-selling-gravitrees&quot;&gt;Prospects for selling gravitrees&lt;/h2&gt;

&lt;p&gt;People have been telling me for a few years now that I should sell gravitrees.
There’s been a real uptick in this sort of comment lately, and with these new designs, I’m starting to believe it.
I’d love for gravitrees to be cheaply buyable (and it’d certainly be nice to make some profit off them).
A few obstacles here include that&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;3D printing is expensive. Shapeways has a marketplace I can sell through, but the prices are high – including shipping, about 30 bucks for a small gravitree and 50 bucks for a large one &lt;em&gt;without my making any profit!&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;I’m not sure how much people are willing to pay for these.&lt;/li&gt;
  &lt;li&gt;Another manufacturing technique like injection molding would be cheaper, but then you’re running a whole business, with inventory and everything. I’d be curious to know how that works, but I don’t want to run something like that long-term.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A decent plan here seems to be to try to sell at a few local art fairs, gauge interest, and perhaps build an online presence.
If demand seems high enough, it could be worth looking for a business partner to handle productization.
(That seems to be what the artist behind the &lt;a href=&quot;https://kinetrika.com/&quot;&gt;Square Wave&lt;/a&gt; did.)
I’d also be happy to sell the idea to an existing company.
It seems worth getting a patent for gravitrees if they seem likely to be marketable.
Most broadly, if I move forward, seems worth reaching out to other people who have made businesses around comparable toylike products to find out how they did it.
If you have any suggestions or leads here, drop me a line!&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:b&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;While I do feel my bang-per-unit-time for gravitrees has been fairly high, I do actually wonder whether the costs are greater than I’m making them out to be. I think about gravitrees a little every day, usually while idle or doing other things, and presumably I’d be thinking about something else for much of that span, which could add up to a lot. &lt;a href=&quot;#fnref:b&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:c&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The pieces rubbed against each other and didn’t spin freely, plus I put too much faith in the chirality of the pinwheel fans to force the fan to spin in a specific direction in wind. &lt;a href=&quot;#fnref:c&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 23 Jun 2024 02:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/gravitree-update-2024/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/gravitree-update-2024/</guid>
        
        
        <category>random</category>
        
      </item>
    
      <item>
        <title>Household microscopy</title>
        <description>&lt;style&gt;
.hover-container {
  position: relative;
  width: 100%;
}

.image {
  display: block;
  width: 100%;
  height: auto;
}

.overlay {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  right: 0;
  height: 100%;
  width: 100%;
  opacity: 0;
  transition: .1s ease;
  background-color: #000000;
}

.hover-container:hover .overlay {
  opacity: 1;
}

.text {
  color: white;
  font-size: 12px;
  position: absolute;
  top: 10%; /* Closer to the top edge */
  left: 10%; /* Closer to the left edge */
  transform: translate(-5%, -5%); /* Adjust these translate values to fine-tune the position */
  text-align: center;
}
&lt;/style&gt;

&lt;p&gt;I’ve been using a &lt;a href=&quot;https://www.amazon.com/Carson-MicroBrite-60x-120x-Lighted-Microscope/dp/B00LAX52IQ&quot;&gt;small handheld microscope&lt;/a&gt; around my house.
For such a cheap instrument, the world it reveals is truly remarkable.
I highly recommend getting one.
As you look at each of the following images, first guess what it’s a photo of, then mouse over.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;col-6&quot;&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/jacket_scoped.jpg&quot; style=&quot;position: absolute; top: -16%; left: -12%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/jacket.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/screen_scoped.jpg&quot; style=&quot;position: absolute; top: -15%; left: -15%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/screen.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/bread_scoped.jpg&quot; style=&quot;position: absolute; top: -28%; left: -13%; width: 140%; height: 140%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/bread.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; style=&quot;position: absolute; top: -13%; left: -13%; width: 120%; height: 120%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/whiteboard_scoped.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/whiteboard.png&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/table_scoped.jpg&quot; style=&quot;position: absolute; top: -19%; left: -19%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/table.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;div style=&quot;width: 100%; height: 0; padding-bottom: 100%; overflow: hidden; position: relative;&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/magazine_scoped.jpg&quot; style=&quot;position: absolute; top: -19%; left: -15%; width: 130%; height: 130%; object-fit: cover;&quot; /&gt;
                &lt;/div&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/magazine.jpg&quot; class=&quot;image&quot; /&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
&lt;!--         &lt;div class=&quot;col-4&quot;&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; class=&quot;image&quot;&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot;&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;br&gt;
            &lt;div class=&quot;hover-container&quot;&gt;
                &lt;img src=&quot;/img/household_microscopy/feather_scoped.jpg&quot; class=&quot;image&quot;&gt;
                &lt;div class=&quot;overlay&quot;&gt;
                    &lt;img src=&quot;/img/household_microscopy/feather.jpg&quot; class=&quot;image&quot;&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt; --&gt;
        &lt;div class=&quot;col-3&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 11 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/household-microscopy/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/household-microscopy/</guid>
        
        
        <category>fun-science</category>
        
      </item>
    
      <item>
        <title>The sixth lake</title>
        <description>&lt;p&gt;
&lt;video autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; playsinline=&quot;&quot; width=&quot;100%&quot; style=&quot;display:block; margin: 0 auto;&quot;&gt;
    &lt;source src=&quot;/img/boolpool_timelapse/boolpool_timelapse.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;
&lt;/p&gt;

&lt;p&gt;If you visit Tahoe’s Five Lakes and wander off-trail in just the right direction, making your way over granite scree and thin alpine topsoil, past windworn pines and views to infinity, you will reach a sixth lake.
It is perched in a high hollow, frozen and unreachable half the year, quite indifferent to the doings of man. Its shores are lined with evergreens, its face reflects the sky, and every day for thousands of years it has born witness to the drama of the High Sierra.&lt;/p&gt;

&lt;p&gt;We were just warm apes, fast and impatient creatures there for a thrill. We were interlopers, protected by our synthetic fabrics and eating our processed foods. Wrapped all around in our human comforts, it wasn’t so easy for us to really see what was there.&lt;/p&gt;

&lt;p&gt;The lake is animated endlessly by forces too big and slow for most of us to see and understand in realtime. The snow sheets drift ploddingly around the pond like tectonic plates, colliding and melting. The wind dances on the water, rippling first one region, then another, the surface revealing the streaming clouds each time it settles to placidity and scrambling them with the return of the waves, again and again. The pines, too, are duplicated in the pond, their reflections growing downwards, slowly, slowly. The sunlight glows long and white, then blazes orange and begins to fade.&lt;/p&gt;

&lt;p&gt;This drama, or one similar, repeats every day. A single glance finds an armada of powerful natural processes that shape the scene, great and grand and far beyond our control. With a long and patient look, you can start to see them do their work. And the pond bears witness, day after day, year after year.&lt;/p&gt;

&lt;p&gt;It changes you to realize this, to see the processes of nature and know their vastness and unstoppability. A deep quiet settles over you. Perhaps you see that you, too, are a phenomenon of this sort – that a few warm apes appearing and disappearing from the side of the pond isn’t so different from the play of the wind on its surface or a deer’s stopping by.&lt;/p&gt;

&lt;p&gt;It is not easy to see this. I only truly feel this now, typing on my laptop in my comfortable Berkeley home, watching this looping timelapse, letting myself fade from the observer into part of the scene. As I do, I’m reminded of some wise words recently given to me by a friend: “we’re all just here to look around.”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Thanks to Noah Sailer for suggesting a timelapse.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/boolpool-timelapse/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/boolpool-timelapse/</guid>
        
        
        <category>random, personal</category>
        
      </item>
    
      <item>
        <title>Using the Laplacian to take a local average of a function</title>
        <description>&lt;p&gt;The Laplacian operator in $d$ dimensions is defined as $\nabla^2 \equiv \sum_{i=1}^d \frac{\partial^2}{\partial x_i^2}$. It’s widely used to model diffusion processes in physics — for example, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Heat_equation&quot;&gt;heat equation&lt;/a&gt;, which describes the diffusion of heat through a material, is given by $\frac{\partial f(\mathbf{x},t)}{\partial t} = \nabla^2 f(\mathbf{x}, t)$. This operator’s come up in &lt;a href=&quot;/blog/1nn-eigenframework&quot;&gt;my recent thinking about the 1NN algorithm&lt;/a&gt;: in particular, I’ve been trying to write down a linear operator that replaces a function with its local average, and I had a sense that you could probably do this with the Laplacian somehow. In thinking this through, I encountered something neat I hadn’t appreciated before: for any analytic function $f$, it holds that&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div style=&quot;border: 1px solid black; padding: 10px; display: inline-block;&quot;&gt;
$$
\left( e^{\frac{\sigma^2}{2} \nabla^2} f \right)(\mathbf x) = \mathbb{E}_{\mathbf{\boldsymbol{\delta}} \sim \mathcal{N}(0, \sigma^2 \mathbf{I}_d)}[f(\mathbf{x} + \boldsymbol{\delta})].
$$
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;That is, the (exponentiated) Laplacian of a function (LHS) is equal to its local average w.r.t. a Gaussian measure (RHS). The RHS is nonlocal, but the LHS is entirely local, so this has some spooky-action-at-a-distance vibes.&lt;/p&gt;

&lt;p&gt;Why is this the case? I’ll give two explanations in 1D, and it’ll be relatively clear how to extend it to higher dimension.&lt;/p&gt;

&lt;h2 id=&quot;argument-from-discretization-of-space&quot;&gt;Argument from discretization of space&lt;/h2&gt;

&lt;p&gt;The Laplacian can be understood intuitively as the limit of its definition on a discretized lattice as the lattice spacing goes to zero. Suppose that instead of a function over the reals, the function $f$ only takes values on the points $\epsilon \mathbb{Z}$ — that is, ${\ldots, -2\epsilon, -\epsilon, 0, \epsilon, 2\epsilon, \ldots }$ — for some small value of $\epsilon$. We could represent the &lt;em&gt;derivative&lt;/em&gt; of $f$ as&lt;/p&gt;

\[(Df)(x) = \frac{f(x + \epsilon) - f(x)}{\epsilon},\]

&lt;p&gt;where $x \in \epsilon \mathbb{Z}$. Similarly, we can define the Laplacian as&lt;/p&gt;

\[\left( \nabla^2 f \right)(x) = \frac{f(x - \epsilon) - 2 f(x) + f(x + \epsilon)}{\epsilon^2}.\]

&lt;p&gt;If we add the identity to the Laplacian operator, we see that&lt;/p&gt;

\[\left( \left[1 + \frac{\epsilon^2}{4} \nabla^2 \right] f \right)(x) = \frac{f(x - \epsilon) + 2 f(x) + f(x + \epsilon)}{4}.\]

&lt;p&gt;(The choice of $\frac{1}{4}$ as the prefactor here is arbitrary, but will make things simpler.) We see then that the operator $1 + \frac{\epsilon^2}{4} \nabla^2$ takes a weighted average of the function value at a point and its two neighbors (with weights $\frac 14, \frac 12, \frac 14$ respectively).&lt;/p&gt;

&lt;p&gt;We can see this as a single step of a random walk. Taking a dual view where instead of staying fixed at the point $x$, we follow the diffusion of the function mass that &lt;em&gt;started&lt;/em&gt; at $x$, we see that $\frac 14$ of the mass has gone one point to the left, $\frac 12$ of the mass has remained in place, and $\frac 14$ of the mass has moved one point to the right.&lt;/p&gt;

&lt;p&gt;After many steps, a random walk on an infinite lattice approaches a (discretized) Gaussian distribution by the central limit theorem. In particular, if we take $n \gg 1$ steps, the corresponding Gaussian will have a variance of $\frac {\epsilon^2 n}{2}$. If we choose $n = \frac{2 \sigma^2}{\epsilon^2}$, we get a Gaussian with variance $\sigma^2$, which gives us the RHS of the boxed equation above!&lt;/p&gt;

&lt;p&gt;As for the LHS, since we’ve iterated this operator $n$ times, it corresponds to&lt;/p&gt;

\[\left[1 + \frac{\epsilon^2}{4} \nabla^2 \right]^n = \left[1 + \frac{\epsilon^2}{4} \nabla^2 \right]^{\frac{2 \sigma^2}{\epsilon^2}}
\xrightarrow{\epsilon \rightarrow 0}
e^{\frac {\sigma^2} 2 \nabla^2}.\]

&lt;p&gt;Great! Let’s test this conclusion on the eigenfunctions of the Laplacian. Let $f_k(x) = e^{i k x}$. Then&lt;/p&gt;

\[e^{\frac {\sigma^2} 2 \nabla^2} f_k = e^{- \frac {\sigma^2 k^2} 2} f_k\]

&lt;p&gt;and also, using the standard Gaussian integral, we find that&lt;/p&gt;

\[\mathbb{E}_{\delta \sim \mathcal{N}(0, \sigma^2)}[f_k(x + \delta)] = e^{- \frac {\sigma^2 k^2} 2} f_k.\]

&lt;p&gt;Great! Actually, since the boxed relation holds for the complete Fourier basis, it’ll hold for all functions (or at least all functions that equal their Fourier series).&lt;/p&gt;

&lt;h2 id=&quot;argument-from-taylor-series&quot;&gt;Argument from Taylor series&lt;/h2&gt;

&lt;p&gt;Consider the function $f(x) = x^a$ for some $a \in \mathbb{Z}^+$. A standard Gaussian integral yields that&lt;/p&gt;

\[\mathbb{E}_{\delta \sim \mathcal{N}(0,\sigma^2)}[\delta^a] =
\left\{\begin{array}{ll}        \frac{a!}{2^{a/2} (a/2)!} \sigma^a &amp;amp; \text{for } a \text{ even}, \\        0 &amp;amp; \text{for } a \text{ odd}.        \end{array}\right.\]

&lt;p&gt;Similarly, the LHS of the boxed equation gives the same result — this is easiest to show starting by writing out&lt;/p&gt;

\[e^{\frac{\sigma^2}{2} \nabla^2} = \lim_{n \rightarrow \infty} \left[1 + \frac{\sigma^2}{2n} \nabla^2 f \right]^n\]

&lt;p&gt;and then expanding the right hand side. Anyways, the fact that the boxed equation holds for any monomial around zero is sufficient to argue that any function that converges to its Taylor series (that is, any analytic function) satisfies the boxed equation. Neat!&lt;/p&gt;

&lt;p&gt;As a closing thought, there’s a potential paradox raised by the boxed equation, which is: how can you take a &lt;em&gt;nonlocal&lt;/em&gt; average of a function with the Laplacian, which is a local operator?
The answer is that the exponentiation actually means that we’re applying the Laplacian an infinite number of times – it’s rather more believable that this counteracts the locality of the operator, especially in light of our discretized model.&lt;/p&gt;

&lt;p&gt;Actually, one more closing thought: so the boxed equation tells us how to study the local &lt;em&gt;Gaussian&lt;/em&gt; average… what if we wanted, say, the local &lt;em&gt;Laplacian&lt;/em&gt; average, or some other rotation-invariant distribution?
Well, you could just represent that distribution in the basis of Gaussians of different widths, and then you’ve got it – you’ll just have some sum or integral over different values of \(\sigma^2\) on the LHS of the boxed equation.
That seems useful because I actually needed a Laplacian average for the 1NN analysis.&lt;/p&gt;

</description>
        <pubDate>Thu, 06 Jun 2024 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/the-laplacian-and-diffusion/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/the-laplacian-and-diffusion/</guid>
        
        
        <category>research</category>
        
      </item>
    
  </channel>
</rss>
